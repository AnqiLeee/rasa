
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Policies</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/banner.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="Slots" href="../slots/" />
    <link rel="prev" title="Actions" href="../actions/" />

  <!-- Google Tag Manager -->
  <script type="opt-in" data-type="application/javascript" data-name="analytics">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MMHSZCS');</script>
  <!-- End Google Tag Manager -->
   
  
  <meta itemprop="image" content="https://rasa.com/assets/img/facebook-og.png">
  <meta property="og:title" content="Policies" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://rasa.com/assets/img/facebook-og.png" />
  <meta property="og:url" content="https://rasa.com/docs/rasa/core/policies" />
  
    <meta name="description" content="Define and train customized policy configurations to optimize your
contextual assistant for longer context or unseen utterances which
require generalization." />
    <meta itemprop="description" content="Define and train customized policy configurations to optimize your
contextual assistant for longer context or unseen utterances which
require generalization.">
    <meta name="twitter:description" content="Define and train customized policy configurations to optimize your
contextual assistant for longer context or unseen utterances which
require generalization." />
    <meta property="og:description" content="Define and train customized policy configurations to optimize your
contextual assistant for longer context or unseen utterances which
require generalization." />
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Rasa_HQ">
  <meta name="twitter:title" content="Policies">
  <meta name="twitter:creator" content="@Rasa_HQ">
  <meta name="twitter:image" content="https://rasa.com/assets/img/facebook-og.png">

  <link rel="stylesheet" href="../../_static/xq-light.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/fontawesome/css/fontawesome-all.css" type="text/css" />
  <link rel="stylesheet" type="text/css" href="https://rasa.com/assets/css/klaro.css">
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro_config.js"></script>
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro.js"></script>
  <script type="text/javascript" src="https://storage.googleapis.com/docs-theme/clipboard.min.js"></script>
  
    <link rel="icon" sizes="192x192" href="../../_static/icon-192x192.png">
    <link rel="apple-touch-icon" href="../../_static/icon-192x192.png" />
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />


  </head><body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe data-name="analytics" data-src="https://www.googletagmanager.com/ns.html?id=GTM-MMHSZCS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<div class="announcement-banner" data-cookie-id="docsAnnouncementBannerDismissed">
  New episodes of the Rasa Masterclass are out now!
  <a href="https://www.youtube.com/watch?v=rlAQWbhwqLA&list=PL75e0qA87dlHQny7z43NduZHPo6qd-cRc" target="_blank">Watch Now</a>
  <button class="announcement-banner__close">✕</button>
</div>

<div class="nav-top">
  <div class="nav-container">
    <ul class="main-nav nav">
      <li>
      <a href="/docs/" class="brand-link">
          <img src="../../_static/rasa_logo.svg" width="80px" height="40px" title="Rasa logo" alt="Rasa logo">
    	    <span class="logo extension">docs</span>
    	</a>
      </li>
      	
          
      	    <li><a href=/docs/getting-started/>Getting Started</a></li>
      	  
      	
          
	        
      	      <li><a href=/docs/rasa/>Rasa Open Source</a></li>
            
      	  
      	
          
      	    <li><a href=/docs/rasa-x/>Rasa X</a></li>
      	  
      	
    </ul>
    <ul class="secondary-nav nav">
      <li>
        <input type="text" class="search ds-input" placeholder="Search documentation...">
      </li>
      <li>
        <a href="https://github.com/rasaHQ/" target="_blank"><button class="button btn-ghost white"> <i class="fab fa-github"></i>GitHub</button></a>
      </li>
      <li>
        <a href="https://forum.rasa.com" target="_blank"><button class="button"><i class="fas fa-comments"></i> Ask the Community</button></a>
      </li>
    </ul>
  </div>
</div>

  
    
      <div class="sidebar-extended"></div>
    
  

  
    
      <div class="document">
    
  

    
      
        
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/installation/">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/rasa-tutorial/">Rasa Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/command-line-interface/">Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/architecture/">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/messaging-and-voice-channels/">Messaging and Voice Channels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/evaluating-models/">Evaluating Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/running-the-server/">Running the Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/running-rasa-with-docker/">Running Rasa with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/cloud-storage/">Cloud Storage</a></li>
</ul>
<p class="caption"><span class="caption-text">NLU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/using-nlu-only/">Using NLU Only</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/training-data-format/">Training Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/choosing-a-pipeline/">Choosing a Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/language-support/">Language Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/entity-extraction/">Entity Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/components/">Components</a></li>
</ul>
<p class="caption"><span class="caption-text">Core</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stories/">Stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domains/">Domains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../responses/">Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../actions/">Actions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slots/">Slots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../forms/">Forms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interactive-learning/">Interactive Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fallback-actions/">Fallback Actions</a></li>
</ul>
<p class="caption"><span class="caption-text">Conversation Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/dialogue-elements/">Dialogue Elements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/small-talk/">Small Talk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/completing-tasks/">Completing Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/guiding-users/">Guiding Users</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/action-server/">Action Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/http-api/">HTTP API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/jupyter-notebooks/">Jupyter Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/agent/">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/custom-nlu-components/">Custom NLU Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/events/">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker/">Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker-stores/">Tracker Stores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/event-brokers/">Event Brokers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/featurization/">Featurization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration-guide/">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog/">Rasa Change Log</a></li>
</ul>

<div class="versions">
    <p class="caption">Versions</p>
    <div class="versions-content">
      <div>
        <span class="current-version">
          viewing: 1.0.9
        </span>
      </div>
      <div class="other-versions">
          <p>tags</p>
          <div class="dropdown-content">
              <a href="../../../1.7.1/core/policies/">1.7.1</a>
              <a href="../../../1.7.0/core/policies/">1.7.0</a>
              <a href="../../../1.6.2/core/policies/">1.6.2</a>
              <a href="../../../1.6.1/core/policies/">1.6.1</a>
              <a href="../../../1.6.0/core/policies/">1.6.0</a>
              <a href="../../../1.5.3/core/policies/">1.5.3</a>
              <a href="../../../1.4.6/core/policies/">1.4.6</a>
              <a href="../../../1.3.10/core/policies/">1.3.10</a>
              <a href="../../../1.2.9/core/policies/">1.2.9</a>
              <a href="../../../1.1.8/core/policies/">1.1.8</a>
              <a href="../../../1.0.9/core/policies/">1.0.9</a>
          </div>
          <p>branches</p>
          <div class="dropdown-content">
              <a href="../../../master/core/policies/">master</a>
          </div>
      </div>
    </div>
</div>


        </div>
      </div>
      
    
      
        
      
        <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  


    
    



    <p class="scv-banner"><a href="../../../1.7.1/core/policies/"><b>Warning:</b> This document is for an old version of Rasa. The latest version is 1.7.1.</a></p>
<div class="section" id="policies">
<span id="id1"></span><h1>Policies<a class="headerlink" href="#policies" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#data-augmentation" id="id5">Data Augmentation</a></li>
<li><a class="reference internal" href="#configuring-policies" id="id6">Configuring Policies</a></li>
<li><a class="reference internal" href="#max-history" id="id7">Max History</a></li>
<li><a class="reference internal" href="#keras-policy" id="id8">Keras Policy</a></li>
<li><a class="reference internal" href="#embedding-policy" id="id9">Embedding Policy</a></li>
<li><a class="reference internal" href="#memoization-policy" id="id10">Memoization Policy</a></li>
<li><a class="reference internal" href="#mapping-policy" id="id11">Mapping Policy</a></li>
<li><a class="reference internal" href="#fallback-policy" id="id12">Fallback Policy</a></li>
<li><a class="reference internal" href="#two-stage-fallback-policy" id="id13">Two-Stage Fallback Policy</a></li>
<li><a class="reference internal" href="#form-policy" id="id14">Form Policy</a></li>
</ul>
</div>
<div class="section" id="data-augmentation">
<h2><a class="toc-backref" href="#id5">Data Augmentation</a><a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h2>
<p>When you train a model, by default Rasa Core will create
longer stories by randomly gluing together
the ones in your stories files.
This is because if you have stories like:</p>
<div class="highlight-story notranslate"><div class="highlight"><pre><span></span><span class="gh"># thanks</span>
<span class="vm">* thankyou</span>
<span class="vm">   </span>- utter_youarewelcome

<span class="gh"># bye</span>
<span class="vm">* goodbye</span>
<span class="vm">   </span>- utter_goodbye
</pre></div>
</div>
<p>You actually want to teach your policy to <strong>ignore</strong> the dialogue history
when it isn’t relevant and just respond with the same action no matter
what happened before.</p>
<p>You can alter this behaviour with the <code class="docutils literal notranslate"><span class="pre">--augmentation</span></code> flag.
Which allows you to set the <code class="docutils literal notranslate"><span class="pre">augmentation_factor</span></code>.
The <code class="docutils literal notranslate"><span class="pre">augmentation_factor</span></code> determines how many augmented stories are
subsampled during training. Subsampling of the augmented stories is done in order to
not get too many stories from augmentation, since their number
can become very large quickly.
The number of sampled stories is <code class="docutils literal notranslate"><span class="pre">augmentation_factor</span></code> x10.
By default augmentation is set to 20, resulting in a maximum of 200 augmented stories.</p>
<p><code class="docutils literal notranslate"><span class="pre">--augmentation</span> <span class="pre">0</span></code> disables all augmentation behavior.
The memoization based policies are not affected by augmentation
(independent of the <code class="docutils literal notranslate"><span class="pre">augmentation_factor</span></code>) and will automatically
ignore all augmented stories.</p>
</div>
<div class="section" id="configuring-policies">
<span id="policy-file"></span><h2><a class="toc-backref" href="#id6">Configuring Policies</a><a class="headerlink" href="#configuring-policies" title="Permalink to this headline">¶</a></h2>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">rasa.core.policies.Policy</span></code> class decides which action to take
at every step in the conversation.</p>
<p>There are different policies to choose from, and you can include
multiple policies in a single <a class="reference internal" href="../../api/agent/#rasa.core.agent.Agent" title="rasa.core.agent.Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">rasa.core.agent.Agent</span></code></a>. At
every turn, the policy which predicts the next action with the
highest confidence will be used. If two policies predict with equal
confidence, the policy with the higher priority will be used.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Per default a maximum of 10 next actions can be predicted
by the agent after every user message. To update this value
you can set the environment variable <code class="docutils literal notranslate"><span class="pre">MAX_NUMBER_OF_PREDICTIONS</span></code>
to the desired number of maximum predictions.</p>
</div>
<p>Your project’s <code class="docutils literal notranslate"><span class="pre">config.yml</span></code> file takes a <code class="docutils literal notranslate"><span class="pre">policies</span></code> key
which you can use to customize the policies your assistant uses.
In the example below, the last two lines show how to use a custom
policy class and pass arguments to it.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">policies</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;KerasPolicy&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">featurizer</span><span class="p p-Indicator">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">MaxHistoryTrackerFeaturizer</span>
      <span class="l l-Scalar l-Scalar-Plain">max_history</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
      <span class="l l-Scalar l-Scalar-Plain">state_featurizer</span><span class="p p-Indicator">:</span>
        <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">BinarySingleStateFeaturizer</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MemoizationPolicy&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">max_history</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">5</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;FallbackPolicy&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">nlu_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.4</span>
    <span class="l l-Scalar l-Scalar-Plain">core_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
    <span class="l l-Scalar l-Scalar-Plain">fallback_action_name</span><span class="p p-Indicator">:</span> <span class="s">&quot;my_fallback_action&quot;</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;path.to.your.policy.class&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">arg1</span><span class="p p-Indicator">:</span> <span class="s">&quot;...&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="max-history">
<h2><a class="toc-backref" href="#id7">Max History</a><a class="headerlink" href="#max-history" title="Permalink to this headline">¶</a></h2>
<p>One important hyperparameter for Rasa Core policies is the <code class="docutils literal notranslate"><span class="pre">max_history</span></code>.
This controls how much dialogue history the model looks at to decide which
action to take next.</p>
<p>You can set the <code class="docutils literal notranslate"><span class="pre">max_history</span></code> by passing it to your policy’s <code class="docutils literal notranslate"><span class="pre">Featurizer</span></code>
in the policy configuration yaml file.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Only the <code class="docutils literal notranslate"><span class="pre">MaxHistoryTrackerFeaturizer</span></code> uses a max history,
whereas the <code class="docutils literal notranslate"><span class="pre">FullDialogueTrackerFeaturizer</span></code> always looks at
the full conversation history. See <a class="reference internal" href="../../api/featurization/#featurization"><span class="std std-ref">Featurization</span></a> for details.</p>
</div>
<p>As an example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">out_of_scope</span></code> intent which
describes off-topic user messages. If your bot sees this intent multiple
times in a row, you might want to tell the user what you <cite>can</cite> help them
with. So your story might look like this:</p>
<div class="highlight-story notranslate"><div class="highlight"><pre><span></span><span class="vm">* out_of_scope</span>
<span class="vm">   </span>- utter_default
<span class="vm">* out_of_scope</span>
<span class="vm">   </span>- utter_default
<span class="vm">* out_of_scope</span>
<span class="vm">   </span>- utter_help_message
</pre></div>
</div>
<p>For Rasa Core to learn this pattern, the <code class="docutils literal notranslate"><span class="pre">max_history</span></code>
has to be <cite>at least</cite> 3.</p>
<p>If you increase your <code class="docutils literal notranslate"><span class="pre">max_history</span></code>, your model will become bigger and
training will take longer. If you have some information that should
affect the dialogue very far into the future, you should store it as a
slot. Slot information is always available for every featurizer.</p>
</div>
<div class="section" id="keras-policy">
<h2><a class="toc-backref" href="#id8">Keras Policy</a><a class="headerlink" href="#keras-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> uses a neural network implemented in
<a class="reference external" href="http://keras.io">Keras</a> to select the next action.
The default architecture is based on an LSTM, but you can override the
<code class="docutils literal notranslate"><span class="pre">KerasPolicy.model_architecture</span></code> method to implement your own architecture.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_architecture</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">output_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Build a keras model and return a compiled model.&quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="p">(</span>
        <span class="n">Masking</span><span class="p">,</span>
        <span class="n">LSTM</span><span class="p">,</span>
        <span class="n">Dense</span><span class="p">,</span>
        <span class="n">TimeDistributed</span><span class="p">,</span>
        <span class="n">Activation</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Build Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

    <span class="c1"># the shape of the y vector of the labels,</span>
    <span class="c1"># determines which output from rnn will be used</span>
    <span class="c1"># to calculate the loss</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># y is (num examples, num features) so</span>
        <span class="c1"># only the last output from the rnn is used to</span>
        <span class="c1"># calculate the loss</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># y is (num examples, max_dialogue_len, num features) so</span>
        <span class="c1"># all the outputs from the rnn are used to</span>
        <span class="c1"># calculate the loss, therefore a sequence is returned and</span>
        <span class="c1"># time distributed layer is used</span>

        <span class="c1"># the first value in input_shape is max dialogue_len,</span>
        <span class="c1"># it is set to None, to allow dynamic_rnn creation</span>
        <span class="c1"># during prediction</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot construct the model because&quot;</span>
            <span class="s2">&quot;length of output_shape = </span><span class="si">{}</span><span class="s2"> &quot;</span>
            <span class="s2">&quot;should be 1 or 2.&quot;</span>
            <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">obtain_verbosity</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>and the training is run here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">training_trackers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">DialogueStateTracker</span><span class="p">],</span>
    <span class="n">domain</span><span class="p">:</span> <span class="n">Domain</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="c1"># set numpy random seed</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">featurize_for_training</span><span class="p">(</span><span class="n">training_trackers</span><span class="p">,</span> <span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1"># noinspection PyPep8Naming</span>
    <span class="n">shuffled_X</span><span class="p">,</span> <span class="n">shuffled_y</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">shuffled_X_y</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="c1"># set random seed in tf</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tf_config</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_architecture</span><span class="p">(</span>
                    <span class="n">shuffled_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">shuffled_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Fitting model with </span><span class="si">{}</span><span class="s2"> total samples and a &quot;</span>
                <span class="s2">&quot;validation split of </span><span class="si">{}</span><span class="s2">&quot;</span>
                <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_data</span><span class="o">.</span><span class="n">num_examples</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_split</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># filter out kwargs that cannot be passed to fit</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_valid_params</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">shuffled_X</span><span class="p">,</span>
                <span class="n">shuffled_y</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">obtain_verbosity</span><span class="p">(),</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span>
            <span class="p">)</span>
            <span class="c1"># the default parameter for epochs in keras fit is 1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">defaults</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Done fitting keras policy model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can implement the model of your choice by overriding these methods,
or initialize <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> with pre-defined <code class="docutils literal notranslate"><span class="pre">keras</span> <span class="pre">model</span></code>.</p>
<p>In order to get reproducible training results for the same inputs you can
set the <code class="docutils literal notranslate"><span class="pre">random_seed</span></code> attribute of the <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> to any integer.</p>
</div>
<div class="section" id="embedding-policy">
<span id="id2"></span><h2><a class="toc-backref" href="#id9">Embedding Policy</a><a class="headerlink" href="#embedding-policy" title="Permalink to this headline">¶</a></h2>
<p>The Recurrent Embedding Dialogue Policy (REDP)
described in our paper: <a class="reference external" href="https://arxiv.org/abs/1811.11707">https://arxiv.org/abs/1811.11707</a></p>
<p>This policy has a pre-defined architecture, which comprises the
following steps:</p>
<blockquote>
<div><ul class="simple">
<li>apply dense layers to create embeddings for user intents,
entities and system actions including previous actions and slots;</li>
<li>use the embeddings of previous user inputs as a user memory
and embeddings of previous system actions as a system memory;</li>
<li>concatenate user input, previous system action and slots
embeddings for current time into an input vector to rnn;</li>
<li>using user and previous system action embeddings from the input
vector, calculate attention probabilities over the user and
system memories (for system memory, this policy uses
<a class="reference external" href="https://arxiv.org/abs/1410.5401">NTM mechanism</a> with attention
by location);</li>
<li>sum the user embedding and user attention vector and feed it
and the embeddings of the slots as an input to an LSTM cell;</li>
<li>apply a dense layer to the output of the LSTM to get a raw
recurrent embedding of a dialogue;</li>
<li>sum this raw recurrent embedding of a dialogue with system
attention vector to create dialogue level embedding, this step
allows the algorithm to repeat previous system action by copying
its embedding vector directly to the current time output;</li>
<li>weight previous LSTM states with system attention probabilities
to get the previous action embedding, the policy is likely payed
attention to;</li>
<li>if the similarity between this previous action embedding and
current time dialogue embedding is high, overwrite current LSTM
state with the one from the time when this action happened;</li>
<li>for each LSTM time step, calculate the similarity between the
dialogue embedding and embedded system actions.
This step is based on the
<a class="reference external" href="https://arxiv.org/abs/1709.03856">StarSpace</a> idea.</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This policy only works with
<code class="docutils literal notranslate"><span class="pre">FullDialogueTrackerFeaturizer(state_featurizer)</span></code>.</p>
</div>
<p>It is recommended to use
<code class="docutils literal notranslate"><span class="pre">state_featurizer=LabelTokenizerSingleStateFeaturizer(...)</span></code>
(see <a class="reference internal" href="../../api/featurization/#featurization"><span class="std std-ref">Featurization</span></a> for details).</p>
<p><strong>Configuration:</strong></p>
<blockquote>
<div><p>Configuration parameters can be passed as parameters to the
<code class="docutils literal notranslate"><span class="pre">EmbeddingPolicy</span></code> within the policy configuration file.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Pass an appropriate number of <code class="docutils literal notranslate"><span class="pre">epochs</span></code> to the <code class="docutils literal notranslate"><span class="pre">EmbeddingPolicy</span></code>,
otherwise the policy will be trained only for <code class="docutils literal notranslate"><span class="pre">1</span></code>
epoch. Since this is an embedding based policy, it requires a large
number of epochs, which depends on the complexity of the
training data and whether attention is used or not.</p>
</div>
<p>The main feature of this policy is an <strong>attention</strong> mechanism over
previous user input and system actions.
<strong>Attention is turned on by default</strong>; in order to turn it off,
configure the following parameters:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">attn_before_rnn</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will use
attention mechanism over previous user input, default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">attn_after_rnn</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will use
attention mechanism over previous system actions and will be
able to copy previously executed action together with LSTM’s
hidden state from its history, default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">sparse_attention</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> <code class="docutils literal notranslate"><span class="pre">sparsemax</span></code> will be used
instead of <code class="docutils literal notranslate"><span class="pre">softmax</span></code> for attention probabilities, default
<code class="docutils literal notranslate"><span class="pre">false</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">attn_shift_range</span></code> the range of allowed location-based
attention shifts for system memory (<code class="docutils literal notranslate"><span class="pre">attn_after_rnn</span></code>), see
<a class="reference external" href="https://arxiv.org/abs/1410.5401">https://arxiv.org/abs/1410.5401</a> for details;</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Attention requires larger values of <code class="docutils literal notranslate"><span class="pre">epochs</span></code> and takes longer
to train. But it can learn more complicated and nonlinear behaviour.</p>
</div>
<p>The algorithm also has hyper-parameters to control:</p>
<blockquote>
<div><ul>
<li><p class="first">neural network’s architecture:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_a</span></code> sets a list of hidden layers
sizes before embedding layer for user inputs, the number
of hidden layers is equal to the length of the list;</li>
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_b</span></code> sets a list of hidden layers
sizes before embedding layer for system actions, the number
of hidden layers is equal to the length of the list;</li>
<li><code class="docutils literal notranslate"><span class="pre">rnn_size</span></code> sets the number of units in the LSTM cell;</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">training:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">layer_norm</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> layer normalization for lstm
cell is turned on,  default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> sets the number of training examples in one
forward/backward pass, the higher the batch size, the more
memory space you’ll need;</li>
<li><code class="docutils literal notranslate"><span class="pre">epochs</span></code> sets the number of times the algorithm will see
training data, where one <code class="docutils literal notranslate"><span class="pre">epoch</span></code> equals one forward pass and
one backward pass of all the training examples;</li>
<li><code class="docutils literal notranslate"><span class="pre">random_seed</span></code> if set to any int will get reproducible
training results for the same inputs;</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">embedding:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">embed_dim</span></code> sets the dimension of embedding space;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> controls how similar the algorithm should try
to make embedding vectors for correct intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> controls maximum negative similarity for
incorrect intents;</li>
<li><code class="docutils literal notranslate"><span class="pre">similarity_type</span></code> sets the type of the similarity,
it should be either <code class="docutils literal notranslate"><span class="pre">cosine</span></code> or <code class="docutils literal notranslate"><span class="pre">inner</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">num_neg</span></code> sets the number of incorrect intent labels,
the algorithm will minimize their similarity to the user
input during training;</li>
<li><code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm only
minimizes maximum similarity over incorrect intent labels;</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">regularization:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">C2</span></code> sets the scale of L2 regularization</li>
<li><code class="docutils literal notranslate"><span class="pre">C_emb</span></code> sets the scale of how important is to minimize
the maximum similarity between embeddings of different
intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_a</span></code> sets the dropout rate between hidden
layers before embedding layer for user inputs;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_b</span></code> sets the dropout rate between hidden layers
before embedding layer for system actions;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_rnn</span></code> sets the recurrent dropout rate on
the LSTM hidden state <a class="reference external" href="https://arxiv.org/abs/1603.05118">https://arxiv.org/abs/1603.05118</a>;</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">train accuracy calculation:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">evaluate_every_num_epochs</span></code> sets how often to calculate
train accuracy, small values may hurt performance;</li>
<li><code class="docutils literal notranslate"><span class="pre">evaluate_on_num_examples</span></code> how many examples to use for
calculation of train accuracy, large values may hurt
performance.</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Droprate should be between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, e.g.
<code class="docutils literal notranslate"><span class="pre">droprate=0.1</span></code> would drop out <code class="docutils literal notranslate"><span class="pre">10%</span></code> of input units.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For <code class="docutils literal notranslate"><span class="pre">cosine</span></code> similarity <code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> should
be between <code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is an option to use linearly increasing batch size.
The idea comes from <a class="reference external" href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>.
In order to do it pass a list to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, e.g.
<code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">[8,</span> <span class="pre">32]</span></code> (default behaviour). If constant
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is required, pass an <code class="docutils literal notranslate"><span class="pre">int</span></code>, e.g.
<code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">8</span></code>.</p>
</div>
<p>These parameters can be specified in the policy configuration file.
The default values are defined in <code class="docutils literal notranslate"><span class="pre">EmbeddingPolicy.defaults</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># nn architecture</span>
    <span class="c1"># a list of hidden layers sizes before user embed layer</span>
    <span class="c1"># number of hidden layers is equal to the length of this list</span>
    <span class="s2">&quot;hidden_layers_sizes_a&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="c1"># a list of hidden layers sizes before bot embed layer</span>
    <span class="c1"># number of hidden layers is equal to the length of this list</span>
    <span class="s2">&quot;hidden_layers_sizes_b&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="c1"># number of units in rnn cell</span>
    <span class="s2">&quot;rnn_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="c1"># training parameters</span>
    <span class="c1"># flag if to turn on layer normalization for lstm cell</span>
    <span class="s2">&quot;layer_norm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># initial and final batch sizes - batch size will be</span>
    <span class="c1"># linearly increased for each epoch</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="c1"># number of epochs</span>
    <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># set random seed to any int to get reproducible results</span>
    <span class="s2">&quot;random_seed&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># embedding parameters</span>
    <span class="c1"># dimension size of embedding vectors</span>
    <span class="s2">&quot;embed_dim&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="c1"># how similar the algorithm should try</span>
    <span class="c1"># to make embedding vectors for correct actions</span>
    <span class="s2">&quot;mu_pos&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
    <span class="c1"># maximum negative similarity for incorrect actions</span>
    <span class="s2">&quot;mu_neg&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
    <span class="c1"># the type of the similarity</span>
    <span class="s2">&quot;similarity_type&quot;</span><span class="p">:</span> <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>  <span class="c1"># string &#39;cosine&#39; or &#39;inner&#39;</span>
    <span class="c1"># the number of incorrect actions, the algorithm will minimize</span>
    <span class="c1"># their similarity to the user input during training</span>
    <span class="s2">&quot;num_neg&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="c1"># flag if minimize only maximum similarity over incorrect actions</span>
    <span class="s2">&quot;use_max_sim_neg&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># flag which loss function to use</span>
    <span class="c1"># regularization</span>
    <span class="c1"># the scale of L2 regularization</span>
    <span class="s2">&quot;C2&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="c1"># the scale of how important is to minimize the maximum similarity</span>
    <span class="c1"># between embeddings of different actions</span>
    <span class="s2">&quot;C_emb&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="c1"># scale loss with inverse frequency of bot actions</span>
    <span class="s2">&quot;scale_loss_by_action_counts&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># dropout rate for user nn</span>
    <span class="s2">&quot;droprate_a&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="c1"># dropout rate for bot nn</span>
    <span class="s2">&quot;droprate_b&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="c1"># dropout rate for rnn</span>
    <span class="s2">&quot;droprate_rnn&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="c1"># attention parameters</span>
    <span class="c1"># flag to use attention over user input</span>
    <span class="c1"># as an input to rnn</span>
    <span class="s2">&quot;attn_before_rnn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># flag to use attention over prev bot actions</span>
    <span class="c1"># and copy it to output bypassing rnn</span>
    <span class="s2">&quot;attn_after_rnn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># flag to use `sparsemax` instead of `softmax` for attention</span>
    <span class="s2">&quot;sparse_attention&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># flag to use sparsemax for probs</span>
    <span class="c1"># the range of allowed location-based attention shifts</span>
    <span class="s2">&quot;attn_shift_range&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># if None, set to mean dialogue length / 2</span>
    <span class="c1"># visualization of accuracy</span>
    <span class="c1"># how often calculate train accuracy</span>
    <span class="s2">&quot;evaluate_every_num_epochs&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># small values may hurt performance</span>
    <span class="c1"># how many examples to use for calculation of train accuracy</span>
    <span class="s2">&quot;evaluate_on_num_examples&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># large values may hurt performance</span>
<span class="p">}</span>

</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> is set to a negative value to mimic
the original starspace algorithm in the case
<code class="docutils literal notranslate"><span class="pre">mu_neg</span> <span class="pre">=</span> <span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span> <span class="pre">=</span> <span class="pre">False</span></code>. See
<a class="reference external" href="https://arxiv.org/abs/1709.03856">starspace paper</a> for details.</p>
</div>
</div></blockquote>
</div>
<div class="section" id="memoization-policy">
<h2><a class="toc-backref" href="#id10">Memoization Policy</a><a class="headerlink" href="#memoization-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">MemoizationPolicy</span></code> just memorizes the conversations in your
training data. It predicts the next action with confidence <code class="docutils literal notranslate"><span class="pre">1.0</span></code>
if this exact conversation exists in the training data, otherwise it
predicts <code class="docutils literal notranslate"><span class="pre">None</span></code> with confidence <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p>
</div>
<div class="section" id="mapping-policy">
<span id="id3"></span><h2><a class="toc-backref" href="#id11">Mapping Policy</a><a class="headerlink" href="#mapping-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">MappingPolicy</span></code> can be used to directly map intents to actions. The
mappings are assigned by giving an intent the property <code class="docutils literal notranslate"><span class="pre">triggers</span></code>, e.g.:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">intents</span><span class="p p-Indicator">:</span>
 <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ask_is_bot</span><span class="p p-Indicator">:</span>
     <span class="l l-Scalar l-Scalar-Plain">triggers</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">action_is_bot</span>
</pre></div>
</div>
<p>An intent can only be mapped to at most one action. The bot will run
the mapped action once it receives a message of the triggering intent. Afterwards,
it will listen for the next message. With the next
user message, normal prediction will resume.</p>
<p>If you do not want your intent-action mapping to affect the dialogue
history, the mapped action must return a <code class="docutils literal notranslate"><span class="pre">UserUtteranceReverted()</span></code>
event. This will delete the user’s latest message, along with any events that
happened after it, from the dialogue history. This means you should not
include the intent-action interaction in your stories.</p>
<p>For example, if a user asks “Are you a bot?” off-topic in the middle of the
flow, you probably want to answer without that interaction affecting the next
action prediction. A triggered custom action can do anything, but here’s a
simple example that dispatches a bot utterance and then reverts the interaction:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ActionIsBot</span><span class="p">(</span><span class="n">Action</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot;Revertible mapped action for utter_is_bot&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">&quot;action_is_bot&quot;</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dispatcher</span><span class="p">,</span> <span class="n">tracker</span><span class="p">,</span> <span class="n">domain</span><span class="p">):</span>
    <span class="n">dispatcher</span><span class="o">.</span><span class="n">utter_template</span><span class="p">(</span><span class="s2">&quot;utter_is_bot&quot;</span><span class="p">,</span> <span class="n">tracker</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">UserUtteranceReverted</span><span class="p">()]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you use the <code class="docutils literal notranslate"><span class="pre">MappingPolicy</span></code> to predict bot utterances directly (e.g.
<code class="docutils literal notranslate"><span class="pre">triggers:</span> <span class="pre">utter_{}</span></code>), these interactions must go in your stories, as in this
case there is no <code class="docutils literal notranslate"><span class="pre">UserUtteranceReverted()</span></code> and the
intent and the mapped utterance will appear in the dialogue history.</p>
</div>
</div>
<div class="section" id="fallback-policy">
<span id="id4"></span><h2><a class="toc-backref" href="#id12">Fallback Policy</a><a class="headerlink" href="#fallback-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">FallbackPolicy</span></code> invokes a <a class="reference internal" href="../fallback-actions/#fallback-actions"><span class="std std-ref">fallback action</span></a> if the intent recognition
has a confidence below <code class="docutils literal notranslate"><span class="pre">nlu_threshold</span></code> or if none of the dialogue
policies predict an action with confidence higher than <code class="docutils literal notranslate"><span class="pre">core_threshold</span></code>.</p>
<p><strong>Configuration:</strong></p>
<blockquote>
<div><p>The thresholds and fallback action can be adjusted in the policy configuration
file as parameters of the <code class="docutils literal notranslate"><span class="pre">FallbackPolicy</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">policies</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;FallbackPolicy&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">nlu_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
    <span class="l l-Scalar l-Scalar-Plain">core_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
    <span class="l l-Scalar l-Scalar-Plain">fallback_action_name</span><span class="p p-Indicator">:</span> <span class="s">&#39;action_default_fallback&#39;</span>
</pre></div>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="38%" />
<col width="62%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">nlu_threshold</span></code></td>
<td>Min confidence needed to accept an NLU
prediction</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">core_threshold</span></code></td>
<td>Min confidence needed to accept an action
prediction from Rasa Core</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">fallback_action_name</span></code></td>
<td>Name of the <a class="reference internal" href="../fallback-actions/#fallback-actions"><span class="std std-ref">fallback action</span></a>
to be called if the confidence of intent
or action is below the respective threshold</td>
</tr>
</tbody>
</table>
<p>You can also configure the <code class="docutils literal notranslate"><span class="pre">FallbackPolicy</span></code> in your python code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">rasa.core.policies.fallback</span> <span class="kn">import</span> <span class="n">FallbackPolicy</span>
<span class="kn">from</span> <span class="nn">rasa.core.policies.keras_policy</span> <span class="kn">import</span> <span class="n">KerasPolicy</span>
<span class="kn">from</span> <span class="nn">rasa.core.agent</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="n">fallback</span> <span class="o">=</span> <span class="n">FallbackPolicy</span><span class="p">(</span><span class="n">fallback_action_name</span><span class="o">=</span><span class="s2">&quot;action_default_fallback&quot;</span><span class="p">,</span>
                          <span class="n">core_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                          <span class="n">nlu_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="s2">&quot;domain.yml&quot;</span><span class="p">,</span> <span class="n">policies</span><span class="o">=</span><span class="p">[</span><span class="n">KerasPolicy</span><span class="p">(),</span> <span class="n">fallback</span><span class="p">])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can include either the <code class="docutils literal notranslate"><span class="pre">FallbackPolicy</span></code> or the
<code class="docutils literal notranslate"><span class="pre">TwoStageFallbackPolicy</span></code> in your configuration, but not both.</p>
</div>
</div></blockquote>
</div>
<div class="section" id="two-stage-fallback-policy">
<h2><a class="toc-backref" href="#id13">Two-Stage Fallback Policy</a><a class="headerlink" href="#two-stage-fallback-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">TwoStageFallbackPolicy</span></code> handles low NLU confidence in multiple stages
by trying to disambiguate the user input.</p>
<ul>
<li><p class="first">If a NLU prediction has a low confidence score, the user is asked to affirm
the classification of the intent.</p>
<blockquote>
<div><ul class="simple">
<li>If they affirm, the story continues as if the intent was classified
with high confidence from the beginning.</li>
<li>If they deny, the user is asked to rephrase their message.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Rephrasing</p>
<blockquote>
<div><ul class="simple">
<li>If the classification of the rephrased intent was confident, the story
continues as if the user had this intent from the beginning.</li>
<li>If the rephrased intent was not classified with high confidence, the user
is asked to affirm the classified intent.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Second affirmation</p>
<blockquote>
<div><ul class="simple">
<li>If the user affirms the intent, the story continues as if the user had
this intent from the beginning.</li>
<li>If the user denies, the original intent is classified as the specified
<code class="docutils literal notranslate"><span class="pre">deny_suggestion_intent_name</span></code>, and an ultimate fallback action
is triggered (e.g. a handoff to a human).</li>
</ul>
</div></blockquote>
</li>
</ul>
<p><strong>Configuration:</strong></p>
<blockquote>
<div><p>To use the <code class="docutils literal notranslate"><span class="pre">TwoStageFallbackPolicy</span></code>, include the following in your
policy configuration.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">policies</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">TwoStageFallbackPolicy</span>
    <span class="l l-Scalar l-Scalar-Plain">nlu_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
    <span class="l l-Scalar l-Scalar-Plain">core_threshold</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
    <span class="l l-Scalar l-Scalar-Plain">fallback_core_action_name</span><span class="p p-Indicator">:</span> <span class="s">&quot;action_default_fallback&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">fallback_nlu_action_name</span><span class="p p-Indicator">:</span> <span class="s">&quot;action_default_fallback&quot;</span>
    <span class="l l-Scalar l-Scalar-Plain">deny_suggestion_intent_name</span><span class="p p-Indicator">:</span> <span class="s">&quot;out_of_scope&quot;</span>
</pre></div>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="42%" />
<col width="58%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">nlu_threshold</span></code></td>
<td>Min confidence needed to accept an NLU
prediction</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">core_threshold</span></code></td>
<td>Min confidence needed to accept an action
prediction from Rasa Core</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">fallback_core_action_name</span></code></td>
<td>Name of the <a class="reference internal" href="../fallback-actions/#fallback-actions"><span class="std std-ref">fallback action</span></a>
to be called if the confidence of Rasa
Core action prediction is below the
<code class="docutils literal notranslate"><span class="pre">core_threshold</span></code></td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">fallback_nlu_action_name</span></code></td>
<td>Name of the <a class="reference internal" href="../fallback-actions/#fallback-actions"><span class="std std-ref">fallback action</span></a>
to be called if the confidence of Rasa
NLU intent classification is below the
<code class="docutils literal notranslate"><span class="pre">nlu_threshold</span></code></td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">deny_suggestion_intent_name</span></code></td>
<td>The name of the intent which is used to
detect that the user denies the suggested
intents</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can include either the <code class="docutils literal notranslate"><span class="pre">FallbackPolicy</span></code> or the
<code class="docutils literal notranslate"><span class="pre">TwoStageFallbackPolicy</span></code> in your configuration, but not both.</p>
</div>
</div></blockquote>
</div>
<div class="section" id="form-policy">
<h2><a class="toc-backref" href="#id14">Form Policy</a><a class="headerlink" href="#form-policy" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">FormPolicy</span></code> is an extension of the <code class="docutils literal notranslate"><span class="pre">MemoizationPolicy</span></code> which
handles the filling of forms. Once a <code class="docutils literal notranslate"><span class="pre">FormAction</span></code> is called, the
<code class="docutils literal notranslate"><span class="pre">FormPolicy</span></code> will continually predict the <code class="docutils literal notranslate"><span class="pre">FormAction</span></code> until all required
slots in the form are filled. For more information, see <a class="reference internal" href="../forms/#forms"><span class="std std-ref">Forms</span></a>.</p>
</div>
</div>


	    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	    <script type="text/javascript"> docsearch({
	     apiKey: '1f9e0efb89e98543f6613a60f847b176',
	     indexName: 'rasa',
	     inputSelector: 'body > div.nav-top > .nav-container > .nav > li > input',
	     debug: false // Set debug to true if you want to inspect the dropdown
	    });
	    </script>
          </div>

          <div class="footer">
            <div class="questions">
              Stuck?
              <a class="reference external" href="https://forum.rasa.com" target="_blank">Ask a Question</a>
              or
              <a class="reference external" href="https://github.com/rasahq/rasa/issues" target="_blank">Create an Issue</a>
            </div>
            <div class="social">
              <a href="https://github.com/RasaHQ" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
              <a href="https://stackoverflow.com/search?q=rasa" target="_blank" title="Stack Overflow"><i class="fab fa-stack-overflow"></i></a>
              <a href="https://www.youtube.com/channel/UCJ0V6493mLvqdiVwOKWBODQ" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a>
              <a href="https://twitter.com/rasa_hq" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
            </div>

            <div class="copyright small">
            &copy;2019, Rasa Technologies | <a href="https://rasa.com/imprint/" target="_blank">Imprint</a> | <a href="https://rasa.com/privacy-policy/" target="_blank">Privacy Policy</a>
            
            </div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag(...arguments) {
      dataLayer.push(...arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-87333416-1', {
      'anonymize_ip': true,
    });
  </script>
  <script src="https://rasa.com/assets/js/js.cookies.js"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/userId.js"></script>

  <script type="text/javascript">
    var clipboard = new ClipboardJS('.copyable');
    clipboard.on('success', function(e) {
      gtag('event', e.action, {
        'event_category': 'code',
        'event_label': e.text
      });
      const id = e.text.replace(/ /g,'-');
      document.getElementById(id).classList.add('visible');
      setTimeout(function(){
        document.getElementById(id).classList.remove('visible');},
        800
      );
    });
    clipboard.on('error', function(e) {
      console.log(e);
    });

  </script>

  <!-- Dismissable announcement banner -->
  <script>
    var banners = document.querySelectorAll('.announcement-banner');

    Array.from(banners).forEach(function(banner) {
      var cookie_id = banner.dataset['cookie-id'];

      if (localStorage.getItem(cookie_id) !== 'true') {
        banner.classList.add('announcement-banner--visible');
      }

      var bannerCloseButton = banner.querySelector('.announcement-banner__close');

      bannerCloseButton && bannerCloseButton.addEventListener('click', function() {
        localStorage.setItem(cookie_id, 'true');
        banner.classList.remove('announcement-banner--visible');
      });
    });
  </script>

  <!-- onsite anchor fix (otherwise anchors scroll to far) -->
  <script>
    /* Adapted from https://stackoverflow.com/a/13067009/1906073 */
    (function(document, history, location) {
      var HISTORY_SUPPORT = !!(history && history.pushState);

      var anchorScrolls = {
        ANCHOR_REGEX: /^#[^ ]+$/,
        OFFSET_HEIGHT_PX: 66,

        /**
         * Establish events, and fix initial scroll position if a hash is provided.
         */
        init: function() {
          this.scrollToCurrent();
          $(window).on('hashchange', $.proxy(this, 'scrollToCurrent'));
          $('body').on('click', 'a', $.proxy(this, 'delegateAnchors'));
        },

        /**
         * Return the offset amount to deduct from the normal scroll position.
         * Modify as appropriate to allow for dynamic calculations
         */
        getFixedOffset: function() {
          return this.OFFSET_HEIGHT_PX;
        },

        /**
         * If the provided href is an anchor which resolves to an element on the
         * page, scroll to it.
         * @param  {String} href
         * @return {Boolean} - Was the href an anchor.
         */
        scrollIfAnchor: function(href, pushToHistory) {
          var match, anchorOffset;

          if(!this.ANCHOR_REGEX.test(href)) {
            return false;
          }

          match = document.getElementById(href.slice(1));

          if(match) {
            anchorOffset = $(match).offset().top - this.getFixedOffset();
            $('html, body').animate({ scrollTop: anchorOffset});

            // Add the state to history as-per normal anchor links
            if(HISTORY_SUPPORT && pushToHistory) {
              history.pushState({}, document.title, location.pathname + href);
            }
          }

          return !!match;
        },

        /**
         * Attempt to scroll to the current location's hash.
         */
        scrollToCurrent: function(e) {
          if(this.scrollIfAnchor(window.location.hash) && e) {
            e.preventDefault();
          }
        },

        /**
         * If the click event's target was an anchor, fix the scroll position.
         */
        delegateAnchors: function(e) {
          var elem = e.target;

          if(this.scrollIfAnchor(elem.getAttribute('href'), true)) {
            e.preventDefault();
          }
        }
      };

      $(document).ready($.proxy(anchorScrolls, 'init'));
    })(window.document, window.history, window.location);

  </script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/u-info.js"></script>
      <div class="webchat-banner webchat-banner--hidden">
        <img src="https://rasa.com/assets/img/demo/sara_avatar.png" class="webchat-banner__avatar" alt="">
        👋 I can help you get started with Rasa and answer your technical questions.
        <button class="webchat-banner__close">
          <i class="fas fa-times"></i> 
        </button>
      </div>
      <div id="webchat">
        <script src="../../_static/rasa-webchat.js"></script>
        <script>
          WebChat.default.init({
            selector: "#webchat",
            initPayload: "/greet",
            socketUrl: "https://website-demo.rasa.com/",
            socketPath: "/socket.io",
            title: "Sara",
            subtitle: "I'm still in development",
            profileAvatar: "https://rasa.com/assets/img/demo/sara_avatar.png",
            showCloseButton: true,
            fullScreenMode: false,
            hideWhenNotConnected: false,
            connectOn: "open",
            autoClearCache: true,
            linksOpenTab: false,
            openLauncherImage: "../../_static/chat-icon.svg",
            customMessageDelay: (message) => {
              return 900 + message.length;
            },
            params: {
              storage: "local"
            },
            onWidgetEvent: {
              onChatOpen: () => {
                const webchatBanner = document.querySelector('.webchat-banner');
                if (webchatBanner) {
                  localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                  webchatBanner.classList.add('webchat-banner--hidden');
                }
              }
            }
          });

          try {
            const webchatBanner = document.querySelector('.webchat-banner');

            if (webchatBanner) {
              if (localStorage.getItem('WEBCHAT_BANNER_DISMISSED') !== 'true') {
                webchatBanner.classList.remove('webchat-banner--hidden');
              }

              const webChatBannerClose = document.querySelector('.webchat-banner__close');

              webChatBannerClose && webChatBannerClose.addEventListener('click', function() {
                localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                webchatBanner.classList.add('webchat-banner--hidden');
              });
            }
          } catch (e) {}
        </script>
      </div>
  </body>
</html>