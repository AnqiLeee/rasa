
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Components</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/banner.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="The Rasa Core Dialogue Engine" href="../../core/about/" />
    <link rel="prev" title="Entity Extraction" href="../entity-extraction/" />

  <!-- Google Tag Manager -->
  <script type="opt-in" data-type="application/javascript" data-name="analytics">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MMHSZCS');</script>
  <!-- End Google Tag Manager -->
   
  
  <meta itemprop="image" content="https://rasa.com/assets/img/facebook-og.png">
  <meta property="og:title" content="Components" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://rasa.com/assets/img/facebook-og.png" />
  <meta property="og:url" content="https://rasa.com/docs/rasa/nlu/components" />
  
    <meta name="description" content="Configure the custom components of your ML model to optimise the
processes performed on the user input of your contextual assistant." />
    <meta itemprop="description" content="Configure the custom components of your ML model to optimise the
processes performed on the user input of your contextual assistant.">
    <meta name="twitter:description" content="Configure the custom components of your ML model to optimise the
processes performed on the user input of your contextual assistant." />
    <meta property="og:description" content="Configure the custom components of your ML model to optimise the
processes performed on the user input of your contextual assistant." />
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Rasa_HQ">
  <meta name="twitter:title" content="Components">
  <meta name="twitter:creator" content="@Rasa_HQ">
  <meta name="twitter:image" content="https://rasa.com/assets/img/facebook-og.png">

  <link rel="stylesheet" href="../../_static/xq-light.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/fontawesome/css/fontawesome-all.css" type="text/css" />
  <link rel="stylesheet" type="text/css" href="https://rasa.com/assets/css/klaro.css">
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro_config.js"></script>
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro.js"></script>
  <script type="text/javascript" src="https://storage.googleapis.com/docs-theme/clipboard.min.js"></script>
  
    <link rel="icon" sizes="192x192" href="../../_static/icon-192x192.png">
    <link rel="apple-touch-icon" href="../../_static/icon-192x192.png" />
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />


  </head><body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe data-name="analytics" data-src="https://www.googletagmanager.com/ns.html?id=GTM-MMHSZCS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<div class="announcement-banner" data-cookie-id="docsAnnouncementBannerDismissed">
  New episodes of the Rasa Masterclass are out now!
  <a href="https://www.youtube.com/watch?v=rlAQWbhwqLA&list=PL75e0qA87dlHQny7z43NduZHPo6qd-cRc" target="_blank">Watch Now</a>
  <button class="announcement-banner__close">✕</button>
</div>

<div class="nav-top">
  <div class="nav-container">
    <ul class="main-nav nav">
      <li>
      <a href="/docs/" class="brand-link">
          <img src="../../_static/rasa_logo.svg" width="80px" height="40px" title="Rasa logo" alt="Rasa logo">
    	    <span class="logo extension">docs</span>
    	</a>
      </li>
      	
          
      	    <li><a href=/docs/getting-started/>Getting Started</a></li>
      	  
      	
          
	        
      	      <li><a href=/docs/rasa/>Rasa Open Source</a></li>
            
      	  
      	
          
      	    <li><a href=/docs/rasa-x/>Rasa X</a></li>
      	  
      	
    </ul>
    <ul class="secondary-nav nav">
      <li>
        <input type="text" class="search ds-input" placeholder="Search documentation...">
      </li>
      <li>
        <a href="https://github.com/rasaHQ/" target="_blank"><button class="button btn-ghost white"> <i class="fab fa-github"></i>GitHub</button></a>
      </li>
      <li>
        <a href="https://forum.rasa.com" target="_blank"><button class="button"><i class="fas fa-comments"></i> Ask the Community</button></a>
      </li>
    </ul>
  </div>
</div>

  
    
      <div class="sidebar-extended"></div>
    
  

  
    
      <div class="document">
    
  

    
      
        
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/installation/">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/rasa-tutorial/">Rasa Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/command-line-interface/">Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/architecture/">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/messaging-and-voice-channels/">Messaging and Voice Channels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/evaluating-models/">Evaluating Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/validate-files/">Validate Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/running-the-server/">Running the Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/running-rasa-with-docker/">Running Rasa with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user-guide/cloud-storage/">Cloud Storage</a></li>
</ul>
<p class="caption"><span class="caption-text">NLU</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../using-nlu-only/">Using NLU Only</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training-data-format/">Training Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../choosing-a-pipeline/">Choosing a Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../language-support/">Language Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../entity-extraction/">Entity Extraction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Components</a></li>
</ul>
<p class="caption"><span class="caption-text">Core</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../core/about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/stories/">Stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/domains/">Domains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/responses/">Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/actions/">Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/policies/">Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/slots/">Slots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/forms/">Forms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/interactive-learning/">Interactive Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/fallback-actions/">Fallback Actions</a></li>
</ul>
<p class="caption"><span class="caption-text">Conversation Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/dialogue-elements/">Dialogue Elements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/small-talk/">Small Talk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/completing-tasks/">Completing Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/guiding-users/">Guiding Users</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/action-server/">Action Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/http-api/">HTTP API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/jupyter-notebooks/">Jupyter Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/agent/">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/custom-nlu-components/">Custom NLU Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/events/">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker/">Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker-stores/">Tracker Stores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/event-brokers/">Event Brokers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/training-data-importers/">Training Data Importers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/featurization/">Featurization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration-guide/">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog/">Rasa Change Log</a></li>
</ul>
<p class="caption"><span class="caption-text">Migrate from (beta)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/google-dialogflow-to-rasa/">Dialogflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/facebook-wit-ai-to-rasa/">Wit.ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/microsoft-luis-to-rasa/">LUIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/ibm-watson-to-rasa/">IBM Watson</a></li>
</ul>

<div class="versions">
    <p class="caption">Versions</p>
    <div class="versions-content">
      <div>
        <span class="current-version">
          viewing: 1.1.8
        </span>
      </div>
      <div class="other-versions">
          <p>tags</p>
          <div class="dropdown-content">
              <a href="../../../1.7.1/nlu/components/">1.7.1</a>
              <a href="../../../1.7.0/nlu/components/">1.7.0</a>
              <a href="../../../1.6.2/nlu/components/">1.6.2</a>
              <a href="../../../1.6.1/nlu/components/">1.6.1</a>
              <a href="../../../1.6.0/nlu/components/">1.6.0</a>
              <a href="../../../1.5.3/nlu/components/">1.5.3</a>
              <a href="../../../1.4.6/nlu/components/">1.4.6</a>
              <a href="../../../1.3.10/nlu/components/">1.3.10</a>
              <a href="../../../1.2.9/nlu/components/">1.2.9</a>
              <a href="../../../1.1.8/nlu/components/">1.1.8</a>
              <a href="../../../1.0.9/nlu/components/">1.0.9</a>
          </div>
          <p>branches</p>
          <div class="dropdown-content">
              <a href="../../../master/nlu/components/">master</a>
          </div>
      </div>
    </div>
</div>


        </div>
      </div>
      
    
      
        
      
        <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  


    
    



    <p class="scv-banner"><a href="../../../1.7.1/nlu/components/"><b>Warning:</b> This document is for an old version of Rasa. The latest version is 1.7.1.</a></p>
<div class="section" id="components">
<span id="id1"></span><h1>Components<a class="headerlink" href="#components" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For clarity, we have renamed the pre-defined pipelines to reflect
what they <em>do</em> rather than which libraries they use as of Rasa NLU
0.15. The <code class="docutils literal notranslate"><span class="pre">tensorflow_embedding</span></code> pipeline is now called
<code class="docutils literal notranslate"><span class="pre">supervised_embeddings</span></code>, and <code class="docutils literal notranslate"><span class="pre">spacy_sklearn</span></code> is now known as
<code class="docutils literal notranslate"><span class="pre">pretrained_embeddings_spacy</span></code>. Please update your code if you are using these.</p>
</div>
<p>This is a reference of the configuration options for every built-in
component in Rasa NLU. If you want to build a custom component, check
out <a class="reference internal" href="../../api/custom-nlu-components/#custom-nlu-components"><span class="std std-ref">Custom NLU Components</span></a>.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#word-vector-sources" id="id5">Word Vector Sources</a><ul>
<li><a class="reference internal" href="#mitienlp" id="id6">MitieNLP</a></li>
<li><a class="reference internal" href="#spacynlp" id="id7">SpacyNLP</a></li>
</ul>
</li>
<li><a class="reference internal" href="#featurizers" id="id8">Featurizers</a><ul>
<li><a class="reference internal" href="#mitiefeaturizer" id="id9">MitieFeaturizer</a></li>
<li><a class="reference internal" href="#spacyfeaturizer" id="id10">SpacyFeaturizer</a></li>
<li><a class="reference internal" href="#ngramfeaturizer" id="id11">NGramFeaturizer</a></li>
<li><a class="reference internal" href="#regexfeaturizer" id="id12">RegexFeaturizer</a></li>
<li><a class="reference internal" href="#countvectorsfeaturizer" id="id13">CountVectorsFeaturizer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#intent-classifiers" id="id14">Intent Classifiers</a><ul>
<li><a class="reference internal" href="#keywordintentclassifier" id="id15">KeywordIntentClassifier</a></li>
<li><a class="reference internal" href="#mitieintentclassifier" id="id16">MitieIntentClassifier</a></li>
<li><a class="reference internal" href="#sklearnintentclassifier" id="id17">SklearnIntentClassifier</a></li>
<li><a class="reference internal" href="#embeddingintentclassifier" id="id18">EmbeddingIntentClassifier</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tokenizers" id="id19">Tokenizers</a><ul>
<li><a class="reference internal" href="#whitespacetokenizer" id="id20">WhitespaceTokenizer</a></li>
<li><a class="reference internal" href="#jiebatokenizer" id="id21">JiebaTokenizer</a></li>
<li><a class="reference internal" href="#mitietokenizer" id="id22">MitieTokenizer</a></li>
<li><a class="reference internal" href="#spacytokenizer" id="id23">SpacyTokenizer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#entity-extractors" id="id24">Entity Extractors</a><ul>
<li><a class="reference internal" href="#mitieentityextractor" id="id25">MitieEntityExtractor</a></li>
<li><a class="reference internal" href="#spacyentityextractor" id="id26">SpacyEntityExtractor</a></li>
<li><a class="reference internal" href="#entitysynonymmapper" id="id27">EntitySynonymMapper</a></li>
<li><a class="reference internal" href="#crfentityextractor" id="id28">CRFEntityExtractor</a></li>
<li><a class="reference internal" href="#ducklinghttpextractor" id="id29">DucklingHTTPExtractor</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="word-vector-sources">
<h2><a class="toc-backref" href="#id5">Word Vector Sources</a><a class="headerlink" href="#word-vector-sources" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mitienlp">
<span id="id2"></span><h3><a class="toc-backref" href="#id6">MitieNLP</a><a class="headerlink" href="#mitienlp" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes mitie structures. Every mitie component relies on this,
hence this should be put at the beginning
of every pipeline that uses any mitie components.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">The MITIE library needs a language model file, that <strong>must</strong> be specified in
the configuration:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MitieNLP&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;data/total_word_feature_extractor.dat&quot;</span>
</pre></div>
</div>
<p class="last">For more information where to get that file from, head over to
<a class="reference internal" href="../../user-guide/installation/#install-mitie"><span class="std std-ref">installing MITIE</span></a>.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="spacynlp">
<span id="id3"></span><h3><a class="toc-backref" href="#id7">SpacyNLP</a><a class="headerlink" href="#spacynlp" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spacy language initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes spacy structures. Every spacy component relies on this, hence this should be put at the beginning
of every pipeline that uses any spacy components.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Language model, default will use the configured language.
If the spacy model to be used has a name that is different from the language tag (<code class="docutils literal notranslate"><span class="pre">&quot;en&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;de&quot;</span></code>, etc.),
the model name can be specified using this configuration variable. The name will be passed to <code class="docutils literal notranslate"><span class="pre">spacy.load(name)</span></code>.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;SpacyNLP&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span> <span class="s">&quot;en_core_web_md&quot;</span>

  <span class="c1"># when retrieving word vectors, this will decide if the casing</span>
  <span class="c1"># of the word is relevant. E.g. `hello` and `Hello` will</span>
  <span class="c1"># retrieve the same vector, if set to `false`. For some</span>
  <span class="c1"># applications and models it makes sense to differentiate</span>
  <span class="c1"># between these two words, therefore setting this to `true`.</span>
  <span class="l l-Scalar l-Scalar-Plain">case_sensitive</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="featurizers">
<h2><a class="toc-backref" href="#id8">Featurizers</a><a class="headerlink" href="#featurizers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mitiefeaturizer">
<h3><a class="toc-backref" href="#id9">MitieFeaturizer</a><a class="headerlink" href="#mitiefeaturizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal notranslate"><span class="pre">SklearnIntentClassifier</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first"><a class="reference internal" href="#mitienlp"><span class="std std-ref">MitieNLP</span></a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates feature for intent classification using the MITIE featurizer.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">NOT used by the <code class="docutils literal notranslate"><span class="pre">MitieIntentClassifier</span></code> component. Currently, only <code class="docutils literal notranslate"><span class="pre">SklearnIntentClassifier</span></code> is able
to use precomputed features.</p>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MitieFeaturizer&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="spacyfeaturizer">
<h3><a class="toc-backref" href="#id10">SpacyFeaturizer</a><a class="headerlink" href="#spacyfeaturizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">spacy intent featurizer</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal notranslate"><span class="pre">SklearnIntentClassifier</span></code>)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><a class="reference internal" href="#spacynlp"><span class="std std-ref">SpacyNLP</span></a></td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body">Creates feature for intent classification using the spacy featurizer.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ngramfeaturizer">
<h3><a class="toc-backref" href="#id11">NGramFeaturizer</a><a class="headerlink" href="#ngramfeaturizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Appends char-ngram features to feature vector</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, appends its features to an existing feature vector generated by another intent featurizer</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first"><a class="reference internal" href="#spacynlp"><span class="std std-ref">SpacyNLP</span></a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This featurizer appends character ngram features to a feature vector. During training the component looks for the
most common character sequences (e.g. <code class="docutils literal notranslate"><span class="pre">app</span></code> or <code class="docutils literal notranslate"><span class="pre">ing</span></code>). The added features represent a boolean flag if the
character sequence is present in the word sequence or not.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There needs to be another intent featurizer previous to this one in the pipeline!</p>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;NGramFeaturizer&quot;</span>
  <span class="c1"># Maximum number of ngrams to use when augmenting</span>
  <span class="c1"># feature vectors with character ngrams</span>
  <span class="l l-Scalar l-Scalar-Plain">max_number_of_ngrams</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="regexfeaturizer">
<h3><a class="toc-backref" href="#id12">RegexFeaturizer</a><a class="headerlink" href="#regexfeaturizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">regex feature creation to support intent and entity classification</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">text_features</span></code> and <code class="docutils literal notranslate"><span class="pre">tokens.pattern</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">During training, the regex intent featurizer creates a list of <cite>regular expressions</cite> defined in the training data format.
For each regex, a feature will be set marking whether this expression was found in the input, which will later be fed into intent classifier / entity
extractor to simplify classification (assuming the classifier has learned during the training phase, that this set
feature indicates a certain intent). Regex features for entity extraction are currently only supported by the
<code class="docutils literal notranslate"><span class="pre">CRFEntityExtractor</span></code> component!</p>
<div class="last admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There needs to be a tokenizer previous to this featurizer in the pipeline!</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="countvectorsfeaturizer">
<h3><a class="toc-backref" href="#id13">CountVectorsFeaturizer</a><a class="headerlink" href="#countvectorsfeaturizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that
need bag-of-words representation of intent features
(e.g. <code class="docutils literal notranslate"><span class="pre">EmbeddingIntentClassifier</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features using
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn’s CountVectorizer</a>.
All tokens which consist only of digits (e.g. 123 and 99 but not a123d) will be assigned to the same feature.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the words in the model language cannot be split by whitespace,
a language-specific tokenizer is required in the pipeline before this component
(e.g. using <code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code> for Chinese).</p>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn’s CountVectorizer docs</a>
for detailed description of the configuration parameters.</p>
<p>This featurizer can be configured to use word or character n-grams, using <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> config parameter.
By default <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is set to <code class="docutils literal notranslate"><span class="pre">word</span></code> so word token counts are used as features.
If you want to use character n-grams, set <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> to <code class="docutils literal notranslate"><span class="pre">char</span></code> or <code class="docutils literal notranslate"><span class="pre">char_wb</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Option ‘char_wb’ creates character n-grams only from text inside word boundaries;
n-grams at the edges of words are padded with space.
This option can be used to create <a class="reference external" href="https://arxiv.org/abs/1810.07150">Subword Semantic Hashing</a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For character n-grams do not forget to increase <code class="docutils literal notranslate"><span class="pre">min_ngram</span></code> and <code class="docutils literal notranslate"><span class="pre">max_ngram</span></code> parameters.
Otherwise the vocabulary will contain only single letters</p>
</div>
<p>Handling Out-Of-Vacabulary (OOV) words:</p>
<blockquote>
<div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Enabled only if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is <code class="docutils literal notranslate"><span class="pre">word</span></code>.</p>
</div>
<p>Since the training is performed on limited vocabulary data, it cannot be guaranteed that during prediction
an algorithm will not encounter an unknown word (a word that were not seen during training).
In order to teach an algorithm how to treat unknown words, some words in training data can be substituted by generic word <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>.
In this case during prediction all unknown words will be treated as this generic word <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>.</p>
<p>For example, one might create separate intent <code class="docutils literal notranslate"><span class="pre">outofscope</span></code> in the training data containing messages of different number of <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> s and
maybe some additional general words. Then an algorithm will likely classify a message with unknown words as this intent <code class="docutils literal notranslate"><span class="pre">outofscope</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>This featurizer creates a bag-of-words representation by <strong>counting</strong> words,
so the number of <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> in the sentence might be important.</p>
<ul class="last simple">
<li><code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> set a keyword for unseen words; if training data contains <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> as words in some messages,
during prediction the words that were not seen during training will be substituted with provided <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>;
if <code class="docutils literal notranslate"><span class="pre">OOV_token=None</span></code> (default behaviour) words that were not seen during training will be ignored during prediction time;</li>
<li><code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> set a list of words to be treated as <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> during training; if a list of words that should be treated
as Out-Of-Vacabulary is known, it can be set to <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> instead of manually changing it in trainig data or using custom preprocessor.</li>
</ul>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Providing <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> is optional, training data can contain <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> input manually or by custom additional preprocessor.
Unseen words will be substituted with <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> <strong>only</strong> if this token is present in the training data or <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> list is provided.</p>
</div>
</div></blockquote>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;CountVectorsFeaturizer&quot;</span>
  <span class="c1"># whether to use word or character n-grams</span>
  <span class="c1"># &#39;char_wb&#39; creates character n-grams only inside word boundaries</span>
  <span class="c1"># n-grams at the edges of words are padded with space.</span>
  <span class="l l-Scalar l-Scalar-Plain">analyzer</span><span class="p p-Indicator">:</span> <span class="s">&#39;word&#39;</span>  <span class="c1"># use &#39;char&#39; or &#39;char_wb&#39; for character</span>
  <span class="c1"># the parameters are taken from</span>
  <span class="c1"># sklearn&#39;s CountVectorizer</span>
  <span class="c1"># regular expression for tokens</span>
  <span class="l l-Scalar l-Scalar-Plain">token_pattern</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">r&#39;(?u)\b\w\w+\b&#39;</span>
  <span class="c1"># remove accents during the preprocessing step</span>
  <span class="l l-Scalar l-Scalar-Plain">strip_accents</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># {&#39;ascii&#39;, &#39;unicode&#39;, None}</span>
  <span class="c1"># list of stop words</span>
  <span class="l l-Scalar l-Scalar-Plain">stop_words</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># string {&#39;english&#39;}, list, or None (default)</span>
  <span class="c1"># min document frequency of a word to add to vocabulary</span>
  <span class="c1"># float - the parameter represents a proportion of documents</span>
  <span class="c1"># integer - absolute counts</span>
  <span class="l l-Scalar l-Scalar-Plain">min_df</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># float in range [0.0, 1.0] or int</span>
  <span class="c1"># max document frequency of a word to add to vocabulary</span>
  <span class="c1"># float - the parameter represents a proportion of documents</span>
  <span class="c1"># integer - absolute counts</span>
  <span class="l l-Scalar l-Scalar-Plain">max_df</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1.0</span>  <span class="c1"># float in range [0.0, 1.0] or int</span>
  <span class="c1"># set ngram range</span>
  <span class="l l-Scalar l-Scalar-Plain">min_ngram</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># int</span>
  <span class="l l-Scalar l-Scalar-Plain">max_ngram</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>  <span class="c1"># int</span>
  <span class="c1"># limit vocabulary size</span>
  <span class="l l-Scalar l-Scalar-Plain">max_features</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># int or None</span>
  <span class="c1"># if convert all characters to lowercase</span>
  <span class="l l-Scalar l-Scalar-Plain">lowercase</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>  <span class="c1"># bool</span>
  <span class="c1"># handling Out-Of-Vacabulary (OOV) words</span>
  <span class="c1"># will be converted to lowercase if lowercase is true</span>
  <span class="l l-Scalar l-Scalar-Plain">OOV_token</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>  <span class="c1"># string or None</span>
  <span class="l l-Scalar l-Scalar-Plain">OOV_words</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[]</span>  <span class="c1"># list of strings</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="intent-classifiers">
<h2><a class="toc-backref" href="#id14">Intent Classifiers</a><a class="headerlink" href="#intent-classifiers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="keywordintentclassifier">
<h3><a class="toc-backref" href="#id15">KeywordIntentClassifier</a><a class="headerlink" href="#keywordintentclassifier" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Simple keyword matching intent classifier. Not intended to be used.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first last">This classifier is mostly used as a placeholder. It is able to recognize <cite>hello</cite> and
<cite>goodbye</cite> intents by searching for these keywords in the passed messages.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="mitieintentclassifier">
<h3><a class="toc-backref" href="#id16">MitieIntentClassifier</a><a class="headerlink" href="#mitieintentclassifier" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent classifier (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/examples/python/text_categorizer_pure_model.py">text categorizer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">A tokenizer and a featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This classifier uses MITIE to perform intent classification. The underlying classifier
is using a multi-class linear SVM with a sparse linear kernel (see <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/text_categorizer_trainer.cpp#L222">MITIE trainer code</a>).</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MitieIntentClassifier&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="sklearnintentclassifier">
<h3><a class="toc-backref" href="#id17">SklearnIntentClassifier</a><a class="headerlink" href="#sklearnintentclassifier" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">sklearn intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code> and <code class="docutils literal notranslate"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">A featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.78343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.1485910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.08161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The sklearn intent classifier trains a linear SVM which gets optimized using a grid search. In addition
to other classifiers it also provides rankings of the labels that did not “win”. The spacy intent classifier
needs to be preceded by a featurizer in the pipeline. This featurizer creates the features used for the classification.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">During the training of the SVM a hyperparameter search is run to
find the best parameter set. In the config, you can specify the parameters
that will get tried</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;SklearnIntentClassifier&quot;</span>
  <span class="c1"># Specifies the list of regularization values to</span>
  <span class="c1"># cross-validate over for C-SVM.</span>
  <span class="c1"># This is used with the ``kernel`` hyperparameter in GridSearchCV.</span>
  <span class="l l-Scalar l-Scalar-Plain">C</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">1</span><span class="p p-Indicator">,</span> <span class="nv">2</span><span class="p p-Indicator">,</span> <span class="nv">5</span><span class="p p-Indicator">,</span> <span class="nv">10</span><span class="p p-Indicator">,</span> <span class="nv">20</span><span class="p p-Indicator">,</span> <span class="nv">100</span><span class="p p-Indicator">]</span>
  <span class="c1"># Specifies the kernel to use with C-SVM.</span>
  <span class="c1"># This is used with the ``C`` hyperparameter in GridSearchCV.</span>
  <span class="l l-Scalar l-Scalar-Plain">kernels</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;linear&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="embeddingintentclassifier">
<h3><a class="toc-backref" href="#id18">EmbeddingIntentClassifier</a><a class="headerlink" href="#embeddingintentclassifier" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Embedding intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code> and <code class="docutils literal notranslate"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">A featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.8343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.385910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.28161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The embedding intent classifier embeds user inputs and intent labels into the same space. Supervised embeddings are
trained by maximizing similarity between them. This algorithm is based on
<a class="reference external" href="https://arxiv.org/abs/1709.03856">StarSpace</a>. However, in this implementation
the <code class="docutils literal notranslate"><span class="pre">mu</span></code> parameter is treated differently and additional hidden layers are added together with dropout.
This algorithm also provides similarity rankings of the labels that did not “win”.</p>
<p>The embedding intent classifier needs to be preceded by a featurizer in the pipeline.
This featurizer creates the features used for the embeddings.
It is recommended to use <code class="docutils literal notranslate"><span class="pre">CountVectorsFeaturizer</span></code> that can be optionally preceded
by <code class="docutils literal notranslate"><span class="pre">SpacyNLP</span></code> and <code class="docutils literal notranslate"><span class="pre">SpacyTokenizer</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If during prediction time a message contains <strong>only</strong> words unseen during training,
and no Out-Of-Vacabulary preprocessor was used,
empty intent <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code> is predicted with confidence <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">If you want to split intents into multiple labels, e.g. for predicting multiple intents or for
modeling hierarchical intent structure, use these flags:</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>tokenization of intent labels:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">intent_tokenization_flag</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will split the intent labels into tokens and use bag-of-words representations for them, default <code class="docutils literal notranslate"><span class="pre">false</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">intent_split_symbol</span></code> sets the delimiter string to split the intent labels, default <code class="docutils literal notranslate"><span class="pre">_</span></code>.</li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="docutils">
<dt>The algorithm also has hyperparameters to control:</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>neural network’s architecture:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_a</span></code> sets a list of hidden layer sizes before the embedding layer for user inputs, the number of hidden layers is equal to the length of the list</li>
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_b</span></code> sets a list of hidden layer sizes before the embedding layer for intent labels, the number of hidden layers is equal to the length of the list</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>training:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> sets the number of training examples in one forward/backward pass, the higher the batch size, the more memory space you’ll need;</li>
<li><code class="docutils literal notranslate"><span class="pre">epochs</span></code> sets the number of times the algorithm will see training data, where <code class="docutils literal notranslate"><span class="pre">one</span> <span class="pre">epoch</span></code> = one forward pass and one backward pass of all the training examples;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>embedding:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">embed_dim</span></code> sets the dimension of embedding space;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> controls how similar the algorithm should try to make embedding vectors for correct intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> controls maximum negative similarity for incorrect intents;</li>
<li><code class="docutils literal notranslate"><span class="pre">similarity_type</span></code> sets the type of the similarity, it should be either <code class="docutils literal notranslate"><span class="pre">cosine</span></code> or <code class="docutils literal notranslate"><span class="pre">inner</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">num_neg</span></code> sets the number of incorrect intent labels, the algorithm will minimize their similarity to the user input during training;</li>
<li><code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm only minimizes maximum similarity over incorrect intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">random_seed</span></code> (None or int) An integer sets the random seed for numpy and tensorflow, so that the random initialisation is always the same and produces the same training result</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>regularization:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">C2</span></code> sets the scale of L2 regularization</li>
<li><code class="docutils literal notranslate"><span class="pre">C_emb</span></code> sets the scale of how important is to minimize the maximum similarity between embeddings of different intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate</span></code> sets the dropout rate, it should be between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">droprate=0.1</span></code> would drop out <code class="docutils literal notranslate"><span class="pre">10%</span></code> of input units;</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For <code class="docutils literal notranslate"><span class="pre">cosine</span></code> similarity <code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> should be between <code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is an option to use linearly increasing batch size. The idea comes from <a class="reference external" href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>.
In order to do it pass a list to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">[64,</span> <span class="pre">256]</span></code> (default behaviour).
If constant <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is required, pass an <code class="docutils literal notranslate"><span class="pre">int</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">64</span></code>.</p>
</div>
<p>In the config, you can specify these parameters:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;EmbeddingIntentClassifier&quot;</span>
  <span class="c1"># nn architecture</span>
  <span class="s">&quot;hidden_layers_sizes_a&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,</span> <span class="nv">128</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;hidden_layers_sizes_b&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[]</span>
  <span class="s">&quot;batch_size&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">64</span><span class="p p-Indicator">,</span> <span class="nv">256</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">300</span>
  <span class="c1"># embedding parameters</span>
  <span class="s">&quot;embed_dim&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;mu_pos&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;mu_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">-0.4</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;similarity_type&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;cosine&quot;</span>  <span class="c1"># string &#39;cosine&#39; or &#39;inner&#39;</span>
  <span class="s">&quot;num_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;use_max_sim_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>  <span class="c1"># flag which loss function to use</span>
  <span class="s">&quot;random_seed&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span> <span class="c1"># set to any int to generate a reproducible training result</span>
  <span class="c1"># regularization</span>
  <span class="s">&quot;C2&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.002</span>
  <span class="s">&quot;C_emb&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
  <span class="s">&quot;droprate&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.2</span>
  <span class="c1"># flag for tokenizing intents</span>
  <span class="s">&quot;intent_tokenization_flag&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="s">&quot;intent_split_symbol&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;_&quot;</span>
  <span class="c1"># visualization of accuracy</span>
  <span class="s">&quot;evaluate_every_num_epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>  <span class="c1"># small values may hurt performance</span>
  <span class="s">&quot;evaluate_on_num_examples&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>  <span class="c1"># large values may hurt performance</span>
</pre></div>
</div>
<div class="last admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> is set to a negative value to mimic the original
starspace algorithm in the case <code class="docutils literal notranslate"><span class="pre">mu_neg</span> <span class="pre">=</span> <span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span> <span class="pre">=</span> <span class="pre">False</span></code>.
See <a class="reference external" href="https://arxiv.org/abs/1709.03856">starspace paper</a> for details.</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="tokenizers">
<h2><a class="toc-backref" href="#id19">Tokenizers</a><a class="headerlink" href="#tokenizers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="whitespacetokenizer">
<h3><a class="toc-backref" href="#id20">WhitespaceTokenizer</a><a class="headerlink" href="#whitespacetokenizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using whitespaces as a separator</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates a token for every whitespace separated character sequence. Can be used to define tokens for the MITIE entity
extractor.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Make the tokenizer not case sensitive by adding the <code class="docutils literal notranslate"><span class="pre">case_sensitive:</span> <span class="pre">false</span></code> option. Default being <code class="docutils literal notranslate"><span class="pre">case_sensitive:</span> <span class="pre">true</span></code>.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;WhitespaceTokenizer&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">case_sensitive</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="jiebatokenizer">
<h3><a class="toc-backref" href="#id21">JiebaTokenizer</a><a class="headerlink" href="#jiebatokenizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using Jieba for Chinese language</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the Jieba tokenizer specifically for Chinese
language. For language other than Chinese, Jieba will work as
<code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>. Can be used to define tokens for the
MITIE entity extractor. Make sure to install Jieba, <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">jieba</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">User’s custom dictionary files can be auto loaded by specific the files’ directory path via <code class="docutils literal notranslate"><span class="pre">dictionary_path</span></code></p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;JiebaTokenizer&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">dictionary_path</span><span class="p p-Indicator">:</span> <span class="s">&quot;path/to/custom/dictionary/dir&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>If the <code class="docutils literal notranslate"><span class="pre">dictionary_path</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), then no custom dictionary will be used.</p>
</div>
<div class="section" id="mitietokenizer">
<h3><a class="toc-backref" href="#id22">MitieTokenizer</a><a class="headerlink" href="#mitietokenizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using MITIE</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first"><a class="reference internal" href="#mitienlp"><span class="std std-ref">MitieNLP</span></a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the MITIE tokenizer. Can be used to define
tokens for the MITIE entity extractor.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MitieTokenizer&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="spacytokenizer">
<h3><a class="toc-backref" href="#id23">SpacyTokenizer</a><a class="headerlink" href="#spacytokenizer" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">Tokenizer using spacy</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><a class="reference internal" href="#spacynlp"><span class="std std-ref">SpacyNLP</span></a></td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body">Creates tokens using the spacy tokenizer. Can be used to define
tokens for the MITIE entity extractor.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="entity-extractors">
<h2><a class="toc-backref" href="#id24">Entity Extractors</a><a class="headerlink" href="#entity-extractors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mitieentityextractor">
<h3><a class="toc-backref" href="#id25">MitieEntityExtractor</a><a class="headerlink" href="#mitieentityextractor" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE entity extraction (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/ner_trainer.cpp">MITIE NER trainer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first"><a class="reference internal" href="#mitienlp"><span class="std std-ref">MitieNLP</span></a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;MitieEntityExtractor&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This uses the MITIE entity extraction to find entities in a message. The underlying classifier
is using a multi class linear SVM with a sparse linear kernel and custom features.
The MITIE component does not provide entity confidence values.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;MitieEntityExtractor&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="spacyentityextractor">
<h3><a class="toc-backref" href="#id26">SpacyEntityExtractor</a><a class="headerlink" href="#spacyentityextractor" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spaCy entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first"><a class="reference internal" href="#spacynlp"><span class="std std-ref">SpacyNLP</span></a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;SpacyEntityExtractor&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Using spaCy this component predicts the entities of a message. spacy uses a statistical BILOU transition model.
As of now, this component can only use the spacy builtin entity extraction models and can not be retrained.
This extractor does not provide any confidence scores.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Configure which dimensions, i.e. entity types, the spacy component
should extract. A full list of available dimensions can be found in
the <a class="reference external" href="https://spacy.io/api/annotation#section-named-entities">spaCy documentation</a>.
Leaving the dimensions option unspecified will extract all available dimensions.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;SpacyEntityExtractor&quot;</span>
  <span class="c1"># dimensions to extract</span>
  <span class="l l-Scalar l-Scalar-Plain">dimensions</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;PERSON&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;LOC&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;ORG&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;PRODUCT&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="entitysynonymmapper">
<h3><a class="toc-backref" href="#id27">EntitySynonymMapper</a><a class="headerlink" href="#entitysynonymmapper" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Maps synonymous entity values to the same value.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">modifies existing entities that previous entity extraction components found</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">If the training data contains defined synonyms (by using the <code class="docutils literal notranslate"><span class="pre">value</span></code> attribute on the entity examples).
this component will make sure that detected entity values will be mapped to the same value. For example,
if your training data contains the following examples:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I moved to New York City&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">},</span>
<span class="p">{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I got a new flat in NYC.&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">}]</span>
</pre></div>
</div>
<p class="last">This component will allow you to map the entities <code class="docutils literal notranslate"><span class="pre">New</span> <span class="pre">York</span> <span class="pre">City</span></code> and <code class="docutils literal notranslate"><span class="pre">NYC</span></code> to <code class="docutils literal notranslate"><span class="pre">nyc</span></code>. The entitiy
extraction will return <code class="docutils literal notranslate"><span class="pre">nyc</span></code> even though the message contains <code class="docutils literal notranslate"><span class="pre">NYC</span></code>. When this component changes an
exisiting entity, it appends itself to the processor list of this entity.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="crfentityextractor">
<h3><a class="toc-backref" href="#id28">CRFEntityExtractor</a><a class="headerlink" href="#crfentityextractor" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">conditional random field entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">A tokenizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.874</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;CRFEntityExtractor&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This component implements conditional random fields to do named entity recognition.
CRFs can be thought of as an undirected Markov chain where the time steps are words
and the states are entity classes. Features of the words (capitalisation, POS tagging,
etc.) give probabilities to certain entity classes, as are transitions between
neighbouring entity tags: the most likely set of tags is then calculated and returned.
If POS features are used (pos or pos2), spaCy has to be installed.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;CRFEntityExtractor&quot;</span>
  <span class="c1"># The features are a ``[before, word, after]`` array with</span>
  <span class="c1"># before, word, after holding keys about which</span>
  <span class="c1"># features to use for each word, for example, ``&quot;title&quot;``</span>
  <span class="c1"># in array before will have the feature</span>
  <span class="c1"># &quot;is the preceding word in title case?&quot;.</span>
  <span class="c1"># Available features are:</span>
  <span class="c1"># ``low``, ``title``, ``suffix5``, ``suffix3``, ``suffix2``,</span>
  <span class="c1"># ``suffix1``, ``pos``, ``pos2``, ``prefix5``, ``prefix2``,</span>
  <span class="c1"># ``bias``, ``upper`` and ``digit``</span>
  <span class="l l-Scalar l-Scalar-Plain">features</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[[</span><span class="s">&quot;low&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;title&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;bias&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;suffix3&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;upper&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos2&quot;</span><span class="p p-Indicator">]]</span>

  <span class="c1"># The flag determines whether to use BILOU tagging or not. BILOU</span>
  <span class="c1"># tagging is more rigorous however</span>
  <span class="c1"># requires more examples per entity. Rule of thumb: use only</span>
  <span class="c1"># if more than 100 examples per entity.</span>
  <span class="l l-Scalar l-Scalar-Plain">BILOU_flag</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="l l-Scalar l-Scalar-Plain">max_iterations</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L1 regularization coefficient.</span>
  <span class="l l-Scalar l-Scalar-Plain">L1_c</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L2 regularization coefficient.</span>
  <span class="l l-Scalar l-Scalar-Plain">L2_c</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ducklinghttpextractor">
<span id="id4"></span><h3><a class="toc-backref" href="#id29">DucklingHTTPExtractor</a><a class="headerlink" href="#ducklinghttpextractor" title="Permalink to this headline">¶</a></h3>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Duckling lets you extract common entities like dates,
amounts of money, distances, and others in a number of languages.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Requires:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">53</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">48</span><span class="p">,</span>
                  <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;2017-04-10T00:00:00.000+02:00&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;DucklingHTTPExtractor&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">To use this component you need to run a duckling server. The easiest
option is to spin up a docker container using
<code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">-p</span> <span class="pre">8000:8000</span> <span class="pre">rasa/duckling</span></code>.</p>
<p>Alternatively, you can <a class="reference external" href="https://github.com/facebook/duckling#quickstart">install duckling directly on your
machine</a> and start the server.</p>
<p>Duckling allows to recognize dates, numbers, distances and other structured entities
and normalizes them.
Please be aware that duckling tries to extract as many entity types as possible without
providing a ranking. For example, if you specify both <code class="docutils literal notranslate"><span class="pre">number</span></code> and <code class="docutils literal notranslate"><span class="pre">time</span></code> as dimensions
for the duckling component, the component will extract two entities: <code class="docutils literal notranslate"><span class="pre">10</span></code> as a number and
<code class="docutils literal notranslate"><span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code> as a time from the text <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">will</span> <span class="pre">be</span> <span class="pre">there</span> <span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code>. In such a
situation, your application would have to decide which entity type is be the correct one.
The extractor will always return <cite>1.0</cite> as a confidence, as it is a rule
based system.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Configure which dimensions, i.e. entity types, the duckling component
should extract. A full list of available dimensions can be found in
the <a class="reference external" href="https://duckling.wit.ai/">duckling documentation</a>.
Leaving the dimensions option unspecified will extract all available dimensions.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="p p-Indicator">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="s">&quot;DucklingHTTPExtractor&quot;</span>
  <span class="c1"># url of the running duckling server</span>
  <span class="l l-Scalar l-Scalar-Plain">url</span><span class="p p-Indicator">:</span> <span class="s">&quot;http://localhost:8000&quot;</span>
  <span class="c1"># dimensions to extract</span>
  <span class="l l-Scalar l-Scalar-Plain">dimensions</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;time&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;number&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;amount-of-money&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;distance&quot;</span><span class="p p-Indicator">]</span>
  <span class="c1"># allows you to configure the locale, by default the language is</span>
  <span class="c1"># used</span>
  <span class="l l-Scalar l-Scalar-Plain">locale</span><span class="p p-Indicator">:</span> <span class="s">&quot;de_DE&quot;</span>
  <span class="c1"># if not set the default timezone of Duckling is going to be used</span>
  <span class="c1"># needed to calculate dates from relative expressions like &quot;tomorrow&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">timezone</span><span class="p p-Indicator">:</span> <span class="s">&quot;Europe/Berlin&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


	    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	    <script type="text/javascript"> docsearch({
	     apiKey: '1f9e0efb89e98543f6613a60f847b176',
	     indexName: 'rasa',
	     inputSelector: 'body > div.nav-top > .nav-container > .nav > li > input',
	     debug: false // Set debug to true if you want to inspect the dropdown
	    });
	    </script>
          </div>

          <div class="footer">
            <div class="questions">
              Stuck?
              <a class="reference external" href="https://forum.rasa.com" target="_blank">Ask a Question</a>
              or
              <a class="reference external" href="https://github.com/rasahq/rasa/issues" target="_blank">Create an Issue</a>
            </div>
            <div class="social">
              <a href="https://github.com/RasaHQ" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
              <a href="https://stackoverflow.com/search?q=rasa" target="_blank" title="Stack Overflow"><i class="fab fa-stack-overflow"></i></a>
              <a href="https://www.youtube.com/channel/UCJ0V6493mLvqdiVwOKWBODQ" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a>
              <a href="https://twitter.com/rasa_hq" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
            </div>

            <div class="copyright small">
            &copy;2019, Rasa Technologies | <a href="https://rasa.com/imprint/" target="_blank">Imprint</a> | <a href="https://rasa.com/privacy-policy/" target="_blank">Privacy Policy</a>
            
            </div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag(...arguments) {
      dataLayer.push(...arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-87333416-1', {
      'anonymize_ip': true,
    });
  </script>
  <script src="https://rasa.com/assets/js/js.cookies.js"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/userId.js"></script>

  <script type="text/javascript">
    var clipboard = new ClipboardJS('.copyable');
    clipboard.on('success', function(e) {
      gtag('event', e.action, {
        'event_category': 'code',
        'event_label': e.text
      });
      const id = e.text.replace(/ /g,'-');
      document.getElementById(id).classList.add('visible');
      setTimeout(function(){
        document.getElementById(id).classList.remove('visible');},
        800
      );
    });
    clipboard.on('error', function(e) {
      console.log(e);
    });

  </script>

  <!-- Dismissable announcement banner -->
  <script>
    var banners = document.querySelectorAll('.announcement-banner');

    Array.from(banners).forEach(function(banner) {
      var cookie_id = banner.dataset['cookie-id'];

      if (localStorage.getItem(cookie_id) !== 'true') {
        banner.classList.add('announcement-banner--visible');
      }

      var bannerCloseButton = banner.querySelector('.announcement-banner__close');

      bannerCloseButton && bannerCloseButton.addEventListener('click', function() {
        localStorage.setItem(cookie_id, 'true');
        banner.classList.remove('announcement-banner--visible');
      });
    });
  </script>

  <!-- onsite anchor fix (otherwise anchors scroll to far) -->
  <script>
    /* Adapted from https://stackoverflow.com/a/13067009/1906073 */
    (function(document, history, location) {
      var HISTORY_SUPPORT = !!(history && history.pushState);

      var anchorScrolls = {
        ANCHOR_REGEX: /^#[^ ]+$/,
        OFFSET_HEIGHT_PX: 66,

        /**
         * Establish events, and fix initial scroll position if a hash is provided.
         */
        init: function() {
          this.scrollToCurrent();
          $(window).on('hashchange', $.proxy(this, 'scrollToCurrent'));
          $('body').on('click', 'a', $.proxy(this, 'delegateAnchors'));
        },

        /**
         * Return the offset amount to deduct from the normal scroll position.
         * Modify as appropriate to allow for dynamic calculations
         */
        getFixedOffset: function() {
          return this.OFFSET_HEIGHT_PX;
        },

        /**
         * If the provided href is an anchor which resolves to an element on the
         * page, scroll to it.
         * @param  {String} href
         * @return {Boolean} - Was the href an anchor.
         */
        scrollIfAnchor: function(href, pushToHistory) {
          var match, anchorOffset;

          if(!this.ANCHOR_REGEX.test(href)) {
            return false;
          }

          match = document.getElementById(href.slice(1));

          if(match) {
            anchorOffset = $(match).offset().top - this.getFixedOffset();
            $('html, body').animate({ scrollTop: anchorOffset});

            // Add the state to history as-per normal anchor links
            if(HISTORY_SUPPORT && pushToHistory) {
              history.pushState({}, document.title, location.pathname + href);
            }
          }

          return !!match;
        },

        /**
         * Attempt to scroll to the current location's hash.
         */
        scrollToCurrent: function(e) {
          if(this.scrollIfAnchor(window.location.hash) && e) {
            e.preventDefault();
          }
        },

        /**
         * If the click event's target was an anchor, fix the scroll position.
         */
        delegateAnchors: function(e) {
          var elem = e.target;

          if(this.scrollIfAnchor(elem.getAttribute('href'), true)) {
            e.preventDefault();
          }
        }
      };

      $(document).ready($.proxy(anchorScrolls, 'init'));
    })(window.document, window.history, window.location);

  </script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/u-info.js"></script>
      <div class="webchat-banner webchat-banner--hidden">
        <img src="https://rasa.com/assets/img/demo/sara_avatar.png" class="webchat-banner__avatar" alt="">
        👋 I can help you get started with Rasa and answer your technical questions.
        <button class="webchat-banner__close">
          <i class="fas fa-times"></i> 
        </button>
      </div>
      <div id="webchat">
        <script src="../../_static/rasa-webchat.js"></script>
        <script>
          WebChat.default.init({
            selector: "#webchat",
            initPayload: "/greet",
            socketUrl: "https://website-demo.rasa.com/",
            socketPath: "/socket.io",
            title: "Sara",
            subtitle: "I'm still in development",
            profileAvatar: "https://rasa.com/assets/img/demo/sara_avatar.png",
            showCloseButton: true,
            fullScreenMode: false,
            hideWhenNotConnected: false,
            connectOn: "open",
            autoClearCache: true,
            linksOpenTab: false,
            openLauncherImage: "../../_static/chat-icon.svg",
            customMessageDelay: (message) => {
              return 900 + message.length;
            },
            params: {
              storage: "local"
            },
            onWidgetEvent: {
              onChatOpen: () => {
                const webchatBanner = document.querySelector('.webchat-banner');
                if (webchatBanner) {
                  localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                  webchatBanner.classList.add('webchat-banner--hidden');
                }
              }
            }
          });

          try {
            const webchatBanner = document.querySelector('.webchat-banner');

            if (webchatBanner) {
              if (localStorage.getItem('WEBCHAT_BANNER_DISMISSED') !== 'true') {
                webchatBanner.classList.remove('webchat-banner--hidden');
              }

              const webChatBannerClose = document.querySelector('.webchat-banner__close');

              webChatBannerClose && webChatBannerClose.addEventListener('click', function() {
                localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                webchatBanner.classList.add('webchat-banner--hidden');
              });
            }
          } catch (e) {}
        </script>
      </div>
  </body>
</html>