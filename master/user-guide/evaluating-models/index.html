
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Evaluating Models</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/banner.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="Validate Data" href="../validate-files/" />
    <link rel="prev" title="Custom Connectors" href="../connectors/custom-connectors/" />

  <!-- Google Tag Manager -->
  <script type="opt-in" data-type="application/javascript" data-name="analytics">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MMHSZCS');</script>
  <!-- End Google Tag Manager -->
   
  
  <meta itemprop="image" content="https://rasa.com/assets/img/facebook-og.png">
  <meta property="og:title" content="Evaluating Models" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://rasa.com/assets/img/facebook-og.png" />
  <meta property="og:url" content="https://rasa.com/docs/rasa/user-guide/evaluating-models" />
  
    <meta name="description" content="Evaluate and validate your machine learning models for open source
library Rasa Core to improve the dialogue management of your contextual
AI Assistant." />
    <meta itemprop="description" content="Evaluate and validate your machine learning models for open source
library Rasa Core to improve the dialogue management of your contextual
AI Assistant.">
    <meta name="twitter:description" content="Evaluate and validate your machine learning models for open source
library Rasa Core to improve the dialogue management of your contextual
AI Assistant." />
    <meta property="og:description" content="Evaluate and validate your machine learning models for open source
library Rasa Core to improve the dialogue management of your contextual
AI Assistant." />
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Rasa_HQ">
  <meta name="twitter:title" content="Evaluating Models">
  <meta name="twitter:creator" content="@Rasa_HQ">
  <meta name="twitter:image" content="https://rasa.com/assets/img/facebook-og.png">

  <link rel="stylesheet" href="../../_static/xq-light.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/fontawesome/css/fontawesome-all.css" type="text/css" />
  <link rel="stylesheet" type="text/css" href="https://rasa.com/assets/css/klaro.css">
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro_config.js"></script>
  <script defer type="text/javascript" src="https://rasa.com/assets/js/klaro.js"></script>
  <script type="text/javascript" src="https://storage.googleapis.com/docs-theme/clipboard.min.js"></script>
  
    <link rel="icon" sizes="192x192" href="../../_static/icon-192x192.png">
    <link rel="apple-touch-icon" href="../../_static/icon-192x192.png" />
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />


  </head><body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe data-name="analytics" data-src="https://www.googletagmanager.com/ns.html?id=GTM-MMHSZCS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<div class="announcement-banner" data-cookie-id="docsAnnouncementBannerDismissed">
  New episodes of the Rasa Masterclass are out now!
  <a href="https://www.youtube.com/watch?v=rlAQWbhwqLA&list=PL75e0qA87dlHQny7z43NduZHPo6qd-cRc" target="_blank">Watch Now</a>
  <button class="announcement-banner__close">✕</button>
</div>

<div class="nav-top">
  <div class="nav-container">
    <ul class="main-nav nav">
      <li>
      <a href="/docs/" class="brand-link">
          <img src="../../_static/rasa_logo.svg" width="80px" height="40px" title="Rasa logo" alt="Rasa logo">
    	    <span class="logo extension">docs</span>
    	</a>
      </li>
      	
          
      	    <li><a href=/docs/getting-started/>Getting Started</a></li>
      	  
      	
          
	        
      	      <li><a href=/docs/rasa/>Rasa Open Source</a></li>
            
      	  
      	
          
      	    <li><a href=/docs/rasa-x/>Rasa X</a></li>
      	  
      	
    </ul>
    <ul class="secondary-nav nav">
      <li>
        <input type="text" class="search ds-input" placeholder="Search documentation...">
      </li>
      <li>
        <a href="https://github.com/rasaHQ/" target="_blank"><button class="button btn-ghost white"> <i class="fab fa-github"></i>GitHub</button></a>
      </li>
      <li>
        <a href="https://forum.rasa.com" target="_blank"><button class="button"><i class="fas fa-comments"></i> Ask the Community</button></a>
      </li>
    </ul>
  </div>
</div>

  
    
      <div class="sidebar-extended"></div>
    
  

  
    
      <div class="document">
    
  

    
      
        
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rasa-tutorial/">Tutorial: Rasa Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../building-assistants/">Tutorial: Building Assistants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../command-line-interface/">Command Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../messaging-and-voice-channels/">Messaging and Voice Channels</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Evaluating Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../validate-files/">Validate Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../running-the-server/">Running the Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../running-rasa-with-docker/">Running Rasa with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cloud-storage/">Cloud Storage</a></li>
</ul>
<p class="caption"><span class="caption-text">NLU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/using-nlu-only/">Using NLU Only</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/training-data-format/">Training Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/choosing-a-pipeline/">Choosing a Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/language-support/">Language Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/entity-extraction/">Entity Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlu/components/">Components</a></li>
</ul>
<p class="caption"><span class="caption-text">Core</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../core/about/">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/stories/">Stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/domains/">Domains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/responses/">Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/actions/">Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/policies/">Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/slots/">Slots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/forms/">Forms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/retrieval-actions/">Retrieval Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/interactive-learning/">Interactive Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/fallback-actions/">Fallback Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core/knowledge-bases/">Knowledge Base Actions</a></li>
</ul>
<p class="caption"><span class="caption-text">Conversation Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/dialogue-elements/">Dialogue Elements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/small-talk/">Small Talk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/completing-tasks/">Completing Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dialogue-elements/guiding-users/">Guiding Users</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/action-server/">Action Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/http-api/">HTTP API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/jupyter-notebooks/">Jupyter Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/agent/">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/custom-nlu-components/">Custom NLU Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/rasa-sdk/">Rasa SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/events/">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker/">Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/tracker-stores/">Tracker Stores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/event-brokers/">Event Brokers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/lock-stores/">Lock Stores</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/training-data-importers/">Training Data Importers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/core-featurization/">Featurization of Conversations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration-guide/">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog/">Rasa Open Source Change Log</a></li>
</ul>
<p class="caption"><span class="caption-text">Migrate from (beta)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/google-dialogflow-to-rasa/">Dialogflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/facebook-wit-ai-to-rasa/">Wit.ai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/microsoft-luis-to-rasa/">LUIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migrate-from/ibm-watson-to-rasa/">IBM Watson</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../glossary/">Glossary</a></li>
</ul>

<div class="versions">
    <p class="caption">Versions</p>
    <div class="versions-content">
      <div>
        <span class="current-version">
          viewing: master
        </span>
      </div>
      <div class="other-versions">
          <p>tags</p>
          <div class="dropdown-content">
              <a href="../../../1.7.1/user-guide/evaluating-models/">1.7.1</a>
              <a href="../../../1.7.0/user-guide/evaluating-models/">1.7.0</a>
              <a href="../../../1.6.2/user-guide/evaluating-models/">1.6.2</a>
              <a href="../../../1.6.1/user-guide/evaluating-models/">1.6.1</a>
              <a href="../../../1.6.0/user-guide/evaluating-models/">1.6.0</a>
              <a href="../../../1.5.3/user-guide/evaluating-models/">1.5.3</a>
              <a href="../../../1.4.6/user-guide/evaluating-models/">1.4.6</a>
              <a href="../../../1.3.10/user-guide/evaluating-models/">1.3.10</a>
              <a href="../../../1.2.9/user-guide/evaluating-models/">1.2.9</a>
              <a href="../../../1.1.8/user-guide/evaluating-models/">1.1.8</a>
              <a href="../../../1.0.9/user-guide/evaluating-models/">1.0.9</a>
          </div>
          <p>branches</p>
          <div class="dropdown-content">
              <a href="../../../master/user-guide/evaluating-models/">master</a>
          </div>
      </div>
    </div>
</div>


        </div>
      </div>
      
    
      
        
      
        <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  


    
    



    <p class="scv-banner"><a href="../../../1.7.1/user-guide/evaluating-models/"><b>Warning:</b> This document is for the development version of Rasa. The latest version is 1.7.1.</a></p>
<div class="section" id="evaluating-models">
<span id="id1"></span><h1>Evaluating Models<a class="headerlink" href="#evaluating-models" title="Permalink to this headline">¶</a></h1>

  <div class="edit-link">
    <a class="reference external" href="https://github.com/RasaHQ/rasa/edit/master/docs/user-guide/evaluating-models.rst" target="_blank"><i class="fab fa-github" style="font-size: 85%; padding-right: 4px;"></i>SUGGEST EDITS</a>
  </div><div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#evaluating-an-nlu-model" id="id4">Evaluating an NLU Model</a><ul>
<li><a class="reference internal" href="#comparing-nlu-pipelines" id="id5">Comparing NLU Pipelines</a></li>
<li><a class="reference internal" href="#intent-classification" id="id6">Intent Classification</a></li>
<li><a class="reference internal" href="#response-selection" id="id7">Response Selection</a></li>
<li><a class="reference internal" href="#entity-extraction" id="id8">Entity Extraction</a></li>
<li><a class="reference internal" href="#entity-scoring" id="id9">Entity Scoring</a></li>
</ul>
</li>
<li><a class="reference internal" href="#evaluating-a-core-model" id="id10">Evaluating a Core Model</a></li>
<li><a class="reference internal" href="#comparing-core-configurations" id="id11">Comparing Core Configurations</a></li>
<li><a class="reference internal" href="#end-to-end-evaluation" id="id12">End-to-End Evaluation</a></li>
</ul>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you are looking to tune the hyperparameters of your NLU model,
check out this <a class="reference external" href="https://blog.rasa.com/rasa-nlu-in-depth-part-3-hyperparameters/">tutorial</a>.</p>
</div>
<div class="section" id="evaluating-an-nlu-model">
<span id="nlu-evaluation"></span><h2><a class="toc-backref" href="#id4">Evaluating an NLU Model</a><a class="headerlink" href="#evaluating-an-nlu-model" title="Permalink to this headline">¶</a></h2>
<p>A standard technique in machine learning is to keep some data separate as a <em>test set</em>.
You can <a class="reference internal" href="../command-line-interface/#train-test-split"><span class="std std-ref">split your NLU training data</span></a>
into train and test sets using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rasa data split nlu
</pre></div>
</div>
<p>If you’ve done this, you can see how well your NLU model predicts the test cases using this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rasa <span class="nb">test</span> nlu -u train_test_split/test_data.md --model models/nlu-20180323-145833.tar.gz
</pre></div>
</div>
<p>If you don’t want to create a separate test set, you can
still estimate how well your model generalises using cross-validation.
To do this, add the flag <code class="docutils literal notranslate"><span class="pre">--cross-validation</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rasa <span class="nb">test</span> nlu -u data/nlu.md --config config.yml --cross-validation
</pre></div>
</div>
<p>The full list of options for the script is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>usage: rasa test nlu [-h] [-v] [-vv] [--quiet] [-m MODEL] [-u NLU] [--out OUT]
                     [--successes] [--no-errors] [--histogram HISTOGRAM]
                     [--confmat CONFMAT] [-c CONFIG [CONFIG ...]]
                     [--cross-validation] [-f FOLDS] [-r RUNS]
                     [-p PERCENTAGES [PERCENTAGES ...]] [--no-plot]

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to a trained Rasa model. If a directory is
                        specified, it will use the latest model in this
                        directory. (default: models)
  -u NLU, --nlu NLU     File or folder containing your NLU data. (default:
                        data)
  --out OUT             Output path for any files created during the
                        evaluation. (default: results)
  --successes           If set successful predictions (intent and entities)
                        will be written to a file. (default: False)
  --no-errors           If set incorrect predictions (intent and entities)
                        will NOT be written to a file. (default: False)
  --histogram HISTOGRAM
                        Output path for the confidence histogram. (default:
                        hist.png)
  --confmat CONFMAT     Output path for the confusion matrix plot. (default:
                        confmat.png)
  -c CONFIG [CONFIG ...], --config CONFIG [CONFIG ...]
                        Model configuration file. If a single file is passed
                        and cross validation mode is chosen, cross-validation
                        is performed, if multiple configs or a folder of
                        configs are passed, models will be trained and
                        compared directly. (default: None)
  --no-plot             Don&#39;t render evaluation plots (default: False)

Python Logging Options:
  -v, --verbose         Be verbose. Sets logging level to INFO. (default:
                        None)
  -vv, --debug          Print lots of debugging statements. Sets logging level
                        to DEBUG. (default: None)
  --quiet               Be quiet! Sets logging level to WARNING. (default:
                        None)

Cross Validation:
  --cross-validation    Switch on cross validation mode. Any provided model
                        will be ignored. (default: False)
  -f FOLDS, --folds FOLDS
                        Number of cross validation folds (cross validation
                        only). (default: 5)

Comparison Mode:
  -r RUNS, --runs RUNS  Number of comparison runs to make. (default: 3)
  -p PERCENTAGES [PERCENTAGES ...], --percentages PERCENTAGES [PERCENTAGES ...]
                        Percentages of training data to exclude during
                        comparison. (default: [0, 25, 50, 75])
</pre></div>
</div>
<div class="section" id="comparing-nlu-pipelines">
<span id="id2"></span><h3><a class="toc-backref" href="#id5">Comparing NLU Pipelines</a><a class="headerlink" href="#comparing-nlu-pipelines" title="Permalink to this headline">¶</a></h3>
<p>By passing multiple pipeline configurations (or a folder containing them) to the CLI, Rasa will run
a comparative examination between the pipelines.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ rasa <span class="nb">test</span> nlu --config pretrained_embeddings_spacy.yml supervised_embeddings.yml
  --nlu data/nlu.md --runs <span class="m">3</span> --percentages <span class="m">0</span> <span class="m">25</span> <span class="m">50</span> <span class="m">70</span> <span class="m">90</span>
</pre></div>
</div>
<p>The command in the example above will create a train/test split from your data,
then train each pipeline multiple times with 0, 25, 50, 70 and 90% of your intent data excluded from the training set.
The models are then evaluated on the test set and the f1-score for each exclusion percentage is recorded. This process
runs three times (i.e. with 3 test sets in total) and then a graph is plotted using the means and standard deviations of
the f1-scores.</p>
<p>The f1-score graph - along with all train/test sets, the trained models, classification and error reports - will be saved into a folder
called <code class="docutils literal notranslate"><span class="pre">nlu_comparison_results</span></code>.</p>
</div>
<div class="section" id="intent-classification">
<h3><a class="toc-backref" href="#id6">Intent Classification</a><a class="headerlink" href="#intent-classification" title="Permalink to this headline">¶</a></h3>
<p>The evaluation script will produce a report, confusion matrix,
and confidence histogram for your model.</p>
<p>The report logs precision, recall and f1 measure for
each intent and entity, as well as providing an overall average.
You can save these reports as JSON files using the <code class="docutils literal notranslate"><span class="pre">--report</span></code> argument.</p>
<p>The confusion matrix shows you which
intents are mistaken for others; any samples which have been
incorrectly predicted are logged and saved to a file
called <code class="docutils literal notranslate"><span class="pre">errors.json</span></code> for easier debugging.</p>
<p>The histogram that the script produces allows you to visualise the
confidence distribution for all predictions,
with the volume of correct and incorrect predictions being displayed by
blue and red bars respectively.
Improving the quality of your training data will move the blue
histogram bars to the right and the red histogram bars
to the left of the plot.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">If any of your entities are incorrectly annotated, your evaluation may fail. One common problem
is that an entity cannot stop or start inside a token.
For example, if you have an example for a <code class="docutils literal notranslate"><span class="pre">name</span></code> entity
like <code class="docutils literal notranslate"><span class="pre">[Brian](name)'s</span> <span class="pre">house</span></code>, this is only valid if your tokenizer splits <code class="docutils literal notranslate"><span class="pre">Brian's</span></code> into
multiple tokens. A whitespace tokenizer would not work in this case.</p>
</div>
</div>
<div class="section" id="response-selection">
<h3><a class="toc-backref" href="#id7">Response Selection</a><a class="headerlink" href="#response-selection" title="Permalink to this headline">¶</a></h3>
<p>The evaluation script will produce a combined report for all response selector models in your pipeline.</p>
<p>The report logs precision, recall and f1 measure for
each response, as well as providing an overall average.
You can save these reports as JSON files using the <code class="docutils literal notranslate"><span class="pre">--report</span></code> argument.</p>
</div>
<div class="section" id="entity-extraction">
<h3><a class="toc-backref" href="#id8">Entity Extraction</a><a class="headerlink" href="#entity-extraction" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">CRFEntityExtractor</span></code> is the only entity extractor which you train using your own data,
and so is the only one that will be evaluated. If you use the spaCy or duckling
pre-trained entity extractors, Rasa NLU will not include these in the evaluation.</p>
<p>Rasa NLU will report recall, precision, and f1 measure for each entity type that
<code class="docutils literal notranslate"><span class="pre">CRFEntityExtractor</span></code> is trained to recognize.</p>
</div>
<div class="section" id="entity-scoring">
<h3><a class="toc-backref" href="#id9">Entity Scoring</a><a class="headerlink" href="#entity-scoring" title="Permalink to this headline">¶</a></h3>
<p>To evaluate entity extraction we apply a simple tag-based approach. We don’t consider BILOU tags, but only the
entity type tags on a per token basis. For location entity like “near Alexanderplatz” we
expect the labels <code class="docutils literal notranslate"><span class="pre">LOC</span> <span class="pre">LOC</span></code> instead of the BILOU-based <code class="docutils literal notranslate"><span class="pre">B-LOC</span> <span class="pre">L-LOC</span></code>. Our approach is more lenient
when it comes to evaluation, as it rewards partial extraction and does not punish the splitting of entities.
For example, given the aforementioned entity “near Alexanderplatz” and a system that extracts
“Alexanderplatz”, our approach rewards the extraction of “Alexanderplatz” and punishes the missed out word “near”.
The BILOU-based approach, however, would label this as a complete failure since it expects Alexanderplatz
to be labeled as a last token in an entity (<code class="docutils literal notranslate"><span class="pre">L-LOC</span></code>) instead of a single token entity (<code class="docutils literal notranslate"><span class="pre">U-LOC</span></code>). Note also that
a split extraction of “near” and “Alexanderplatz” would get full scores on our approach and zero on the
BILOU-based one.</p>
<p>Here’s a comparison between the two scoring mechanisms for the phrase “near Alexanderplatz tonight”:</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="24%" />
<col width="27%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">extracted</th>
<th class="head">Simple tags (score)</th>
<th class="head">BILOU tags (score)</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>[near Alexanderplatz](loc) [tonight](time)</td>
<td>loc loc time (3)</td>
<td>B-loc L-loc U-time (3)</td>
</tr>
<tr class="row-odd"><td>[near](loc) [Alexanderplatz](loc) [tonight](time)</td>
<td>loc loc time (3)</td>
<td>U-loc U-loc U-time (1)</td>
</tr>
<tr class="row-even"><td>near [Alexanderplatz](loc) [tonight](time)</td>
<td>O   loc time (2)</td>
<td>O     U-loc U-time (1)</td>
</tr>
<tr class="row-odd"><td>[near](loc) Alexanderplatz [tonight](time)</td>
<td>loc O   time (2)</td>
<td>U-loc O     U-time (1)</td>
</tr>
<tr class="row-even"><td>[near Alexanderplatz tonight](loc)</td>
<td>loc loc loc  (2)</td>
<td>B-loc I-loc L-loc  (1)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="evaluating-a-core-model">
<span id="core-evaluation"></span><h2><a class="toc-backref" href="#id10">Evaluating a Core Model</a><a class="headerlink" href="#evaluating-a-core-model" title="Permalink to this headline">¶</a></h2>
<p>You can evaluate your trained model on a set of test stories
by using the evaluate script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rasa <span class="nb">test</span> core --stories test_stories.md --out results
</pre></div>
</div>
<p>This will print the failed stories to <code class="docutils literal notranslate"><span class="pre">results/failed_stories.md</span></code>.
We count any story as <cite>failed</cite> if at least one of the actions
was predicted incorrectly.</p>
<p>In addition, this will save a confusion matrix to a file called
<code class="docutils literal notranslate"><span class="pre">results/story_confmat.pdf</span></code>. For each action in your domain, the confusion
matrix shows how often the action was correctly predicted and how often an
incorrect action was predicted instead.</p>
<p>The full list of options for the script is:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>usage: rasa test core [-h] [-v] [-vv] [--quiet] [-m MODEL [MODEL ...]]
                      [-s STORIES] [--max-stories MAX_STORIES] [--out OUT]
                      [--e2e] [--endpoints ENDPOINTS]
                      [--fail-on-prediction-errors] [--url URL]
                      [--evaluate-model-directory] [--no-plot]

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL [MODEL ...], --model MODEL [MODEL ...]
                        Path to a pre-trained model. If it is a &#39;tar.gz&#39; file
                        that model file will be used. If it is a directory,
                        the latest model in that directory will be used
                        (exception: &#39;--evaluate-model-directory&#39; flag is set).
                        If multiple &#39;tar.gz&#39; files are provided, all those
                        models will be compared. (default: [None])
  -s STORIES, --stories STORIES
                        File or folder containing your test stories. (default:
                        data)
  --max-stories MAX_STORIES
                        Maximum number of stories to test on. (default: None)
  --out OUT             Output path for any files created during the
                        evaluation. (default: results)
  --e2e, --end-to-end   Run an end-to-end evaluation for combined action and
                        intent prediction. Requires a story file in end-to-end
                        format. (default: False)
  --endpoints ENDPOINTS
                        Configuration file for the connectors as a yml file.
                        (default: None)
  --fail-on-prediction-errors
                        If a prediction error is encountered, an exception is
                        thrown. This can be used to validate stories during
                        tests, e.g. on travis. (default: False)
  --url URL             If supplied, downloads a story file from a URL and
                        trains on it. Fetches the data by sending a GET
                        request to the supplied URL. (default: None)
  --evaluate-model-directory
                        Should be set to evaluate models trained via &#39;rasa
                        train core --config &lt;config-1&gt; &lt;config-2&gt;&#39;. All models
                        in the provided directory are evaluated and compared
                        against each other. (default: False)
  --no-plot             Don&#39;t render evaluation plots (default: False)

Python Logging Options:
  -v, --verbose         Be verbose. Sets logging level to INFO. (default:
                        None)
  -vv, --debug          Print lots of debugging statements. Sets logging level
                        to DEBUG. (default: None)
  --quiet               Be quiet! Sets logging level to WARNING. (default:
                        None)
</pre></div>
</div>
</div>
<div class="section" id="comparing-core-configurations">
<h2><a class="toc-backref" href="#id11">Comparing Core Configurations</a><a class="headerlink" href="#comparing-core-configurations" title="Permalink to this headline">¶</a></h2>
<p>To choose a configuration for your core model, or to choose hyperparameters for a
specific policy, you want to measure how well Rasa Core will <cite>generalise</cite>
to conversations which it hasn’t seen before. Especially in the beginning
of a project, you do not have a lot of real conversations to use to train
your bot, so you don’t just want to throw some away to use as a test set.</p>
<p>Rasa Core has some scripts to help you choose and fine-tune your policy configuration.
Once you are happy with it, you can then train your final configuration on your
full data set. To do this, you first have to train models for your different
configurations. Create two (or more) config files including the policies you want to
compare, and then use the <code class="docutils literal notranslate"><span class="pre">compare</span></code> mode of the train script to train your models:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ rasa train core -c config_1.yml config_2.yml <span class="se">\</span>
  -d domain.yml -s stories_folder --out comparison_models --runs <span class="m">3</span> <span class="se">\</span>
  --percentages <span class="m">0</span> <span class="m">5</span> <span class="m">25</span> <span class="m">50</span> <span class="m">70</span> <span class="m">95</span>
</pre></div>
</div>
<p>For each policy configuration provided, Rasa Core will be trained multiple times
with 0, 5, 25, 50, 70 and 95% of your training stories excluded from the training
data. This is done for multiple runs to ensure consistent results.</p>
<p>Once this script has finished, you can use the evaluate script in <code class="docutils literal notranslate"><span class="pre">compare</span></code>
mode to evaluate the models you just trained:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ rasa <span class="nb">test</span> core -m comparison_models --stories stories_folder
--out comparison_results --evaluate-model-directory
</pre></div>
</div>
<p>This will evaluate each of the models on the provided stories
(can be either training or test set) and plot some graphs
to show you which policy performs best. By evaluating on the full set of stories, you
can measure how well Rasa Core is predicting the held-out stories.</p>
<p>To compare single policies create config files containing only one policy each.
If you’re not sure which policies to compare, we’d recommend trying out the
<code class="docutils literal notranslate"><span class="pre">EmbeddingPolicy</span></code> and the <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> to see which one works better for
you.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This training process can take a long time, so we’d suggest letting it run
somewhere in the background where it can’t be interrupted.</p>
</div>
</div>
<div class="section" id="end-to-end-evaluation">
<span id="id3"></span><h2><a class="toc-backref" href="#id12">End-to-End Evaluation</a><a class="headerlink" href="#end-to-end-evaluation" title="Permalink to this headline">¶</a></h2>
<p>Rasa lets you evaluate dialogues end-to-end, running through
test conversations and making sure that both NLU and Core make correct predictions.</p>
<p>To do this, you need some stories in the end-to-end format,
which includes both the NLU output and the original text.
Here is an example:</p>
<div class="highlight-story notranslate"><div class="highlight"><pre><span></span><span class="gh">## end-to-end story 1</span>
<span class="vm">* greet: </span>hello
   - utter_ask_howcanhelp
<span class="vm">* inform: </span>show me [chinese](cuisine) restaurants
   - utter_ask_location
<span class="vm">* inform: </span>in [Paris](location)
   - utter_ask_price
</pre></div>
</div>
<p>If you’ve saved end-to-end stories as a file called <code class="docutils literal notranslate"><span class="pre">e2e_stories.md</span></code>,
you can evaluate your model against them by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ rasa <span class="nb">test</span> --stories e2e_stories.md --e2e
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Make sure your model file in <code class="docutils literal notranslate"><span class="pre">models</span></code> is a combined <code class="docutils literal notranslate"><span class="pre">core</span></code>
and <code class="docutils literal notranslate"><span class="pre">nlu</span></code> model. If it does not contain an NLU model, Core will use
the default <code class="docutils literal notranslate"><span class="pre">RegexInterpreter</span></code>.</p>
</div>
</div>
</div>


	    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	    <script type="text/javascript"> docsearch({
	     apiKey: '1f9e0efb89e98543f6613a60f847b176',
	     indexName: 'rasa',
	     inputSelector: 'body > div.nav-top > .nav-container > .nav > li > input',
	     debug: false // Set debug to true if you want to inspect the dropdown
	    });
	    </script>
          </div>

          <div class="footer">
            <div class="questions">
              Stuck?
              <a class="reference external" href="https://forum.rasa.com" target="_blank">Ask a Question</a>
              or
              <a class="reference external" href="https://github.com/rasahq/rasa/issues" target="_blank">Create an Issue</a>
            </div>
            <div class="social">
              <a href="https://github.com/RasaHQ" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
              <a href="https://stackoverflow.com/search?q=rasa" target="_blank" title="Stack Overflow"><i class="fab fa-stack-overflow"></i></a>
              <a href="https://www.youtube.com/channel/UCJ0V6493mLvqdiVwOKWBODQ" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a>
              <a href="https://twitter.com/rasa_hq" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
            </div>

            <div class="copyright small">
            &copy;2020, Rasa Technologies | <a href="https://rasa.com/imprint/" target="_blank">Imprint</a> | <a href="https://rasa.com/privacy-policy/" target="_blank">Privacy Policy</a>
            
            </div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag(...arguments) {
      dataLayer.push(...arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-87333416-1', {
      'anonymize_ip': true,
    });
  </script>
  <script src="https://rasa.com/assets/js/js.cookies.js"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/userId.js"></script>

  <script type="text/javascript">
    var clipboard = new ClipboardJS('.copyable');
    clipboard.on('success', function(e) {
      gtag('event', e.action, {
        'event_category': 'code',
        'event_label': e.text
      });
      const id = e.text.replace(/ /g,'-');
      document.getElementById(id).classList.add('visible');
      setTimeout(function(){
        document.getElementById(id).classList.remove('visible');},
        800
      );
    });
    clipboard.on('error', function(e) {
      console.log(e);
    });

  </script>

  <!-- Dismissable announcement banner -->
  <script>
    var banners = document.querySelectorAll('.announcement-banner');

    Array.from(banners).forEach(function(banner) {
      var cookie_id = banner.dataset['cookie-id'];

      if (localStorage.getItem(cookie_id) !== 'true') {
        banner.classList.add('announcement-banner--visible');
      }

      var bannerCloseButton = banner.querySelector('.announcement-banner__close');

      bannerCloseButton && bannerCloseButton.addEventListener('click', function() {
        localStorage.setItem(cookie_id, 'true');
        banner.classList.remove('announcement-banner--visible');
      });
    });
  </script>

  <!-- onsite anchor fix (otherwise anchors scroll to far) -->
  <script>
    /* Adapted from https://stackoverflow.com/a/13067009/1906073 */
    (function(document, history, location) {
      var HISTORY_SUPPORT = !!(history && history.pushState);

      var anchorScrolls = {
        ANCHOR_REGEX: /^#[^ ]+$/,
        OFFSET_HEIGHT_PX: 66,

        /**
         * Establish events, and fix initial scroll position if a hash is provided.
         */
        init: function() {
          this.scrollToCurrent();
          $(window).on('hashchange', $.proxy(this, 'scrollToCurrent'));
          $('body').on('click', 'a', $.proxy(this, 'delegateAnchors'));
        },

        /**
         * Return the offset amount to deduct from the normal scroll position.
         * Modify as appropriate to allow for dynamic calculations
         */
        getFixedOffset: function() {
          return this.OFFSET_HEIGHT_PX;
        },

        /**
         * If the provided href is an anchor which resolves to an element on the
         * page, scroll to it.
         * @param  {String} href
         * @return {Boolean} - Was the href an anchor.
         */
        scrollIfAnchor: function(href, pushToHistory) {
          var match, anchorOffset;

          if(!this.ANCHOR_REGEX.test(href)) {
            return false;
          }

          match = document.getElementById(href.slice(1));

          if(match) {
            anchorOffset = $(match).offset().top - this.getFixedOffset();
            $('html, body').animate({ scrollTop: anchorOffset});

            // Add the state to history as-per normal anchor links
            if(HISTORY_SUPPORT && pushToHistory) {
              history.pushState({}, document.title, location.pathname + href);
            }
          }

          return !!match;
        },

        /**
         * Attempt to scroll to the current location's hash.
         */
        scrollToCurrent: function(e) {
          if(this.scrollIfAnchor(window.location.hash) && e) {
            e.preventDefault();
          }
        },

        /**
         * If the click event's target was an anchor, fix the scroll position.
         */
        delegateAnchors: function(e) {
          var elem = e.target;

          if(this.scrollIfAnchor(elem.getAttribute('href'), true)) {
            e.preventDefault();
          }
        }
      };

      $(document).ready($.proxy(anchorScrolls, 'init'));
    })(window.document, window.history, window.location);

  </script>
  <script type="opt-in" data-name="analytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/u-info.js"></script>
      <div class="webchat-banner webchat-banner--hidden">
        <img src="https://rasa.com/assets/img/demo/sara_avatar.png" class="webchat-banner__avatar" alt="">
        👋 I can help you get started with Rasa and answer your technical questions.
        <button class="webchat-banner__close">
          <i class="fas fa-times"></i> 
        </button>
      </div>
      <div id="webchat">
        <script src="../../_static/rasa-webchat.js"></script>
        <script>
          WebChat.default.init({
            selector: "#webchat",
            initPayload: "/greet",
            socketUrl: "https://website-demo.rasa.com/",
            socketPath: "/socket.io",
            title: "Sara",
            subtitle: "I'm still in development",
            profileAvatar: "https://rasa.com/assets/img/demo/sara_avatar.png",
            showCloseButton: true,
            fullScreenMode: false,
            hideWhenNotConnected: false,
            connectOn: "open",
            autoClearCache: true,
            linksOpenTab: false,
            openLauncherImage: "../../_static/chat-icon.svg",
            customMessageDelay: (message) => {
              return 900 + message.length;
            },
            params: {
              storage: "local"
            },
            onWidgetEvent: {
              onChatOpen: () => {
                const webchatBanner = document.querySelector('.webchat-banner');
                if (webchatBanner) {
                  localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                  webchatBanner.classList.add('webchat-banner--hidden');
                }
              }
            }
          });

          try {
            const webchatBanner = document.querySelector('.webchat-banner');

            if (webchatBanner) {
              if (localStorage.getItem('WEBCHAT_BANNER_DISMISSED') !== 'true') {
                webchatBanner.classList.remove('webchat-banner--hidden');
              }

              const webChatBannerClose = document.querySelector('.webchat-banner__close');

              webChatBannerClose && webChatBannerClose.addEventListener('click', function() {
                localStorage.setItem('WEBCHAT_BANNER_DISMISSED', 'true');
                webchatBanner.classList.add('webchat-banner--hidden');
              });
            }
          } catch (e) {}
        </script>
      </div>
  </body>
</html>